{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b4a5c00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(428, 4) (428,) (428,)\n"
     ]
    },
    {
     "ename": "CatBoostError",
     "evalue": "Invalid loss_function='Logloss': for regressor use RMSE, MultiRMSE, SurvivalAft, MAE, Quantile, LogLinQuantile, Poisson, MAPE, Lq or custom objective object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [45], line 66\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# DML RF\u001b[39;00m\n\u001b[1;32m     51\u001b[0m model_XGB \u001b[38;5;241m=\u001b[39m LinearDML(discrete_treatment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     52\u001b[0m                       model_y \u001b[38;5;241m=\u001b[39m CatBoostRegressor(iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m,\n\u001b[1;32m     53\u001b[0m                                                    depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m                                                    eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     65\u001b[0m                                                    eval_fraction\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m))\n\u001b[0;32m---> 66\u001b[0m \u001b[43mmodel_XGB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mW\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m θ_DMLRF \u001b[38;5;241m=\u001b[39m model_XGB\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# DML NN - First Stage\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/econml/dml/dml.py:753\u001b[0m, in \u001b[0;36mLinearDML.fit\u001b[0;34m(self, Y, T, X, W, sample_weight, freq_weight, sample_var, groups, cache_values, inference)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, Y, T, \u001b[38;5;241m*\u001b[39m, X\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, W\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, freq_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_var\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    715\u001b[0m         cache_values\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, inference\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;124;03m    Estimate the counterfactual model from data, i.e. estimates functions τ(·,·,·), ∂τ(·,·).\u001b[39;00m\n\u001b[1;32m    718\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;124;03m    self\u001b[39;00m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 753\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[43m                       \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreq_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_var\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mcache_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    756\u001b[0m \u001b[43m                       \u001b[49m\u001b[43minference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/econml/dml/dml.py:555\u001b[0m, in \u001b[0;36mDML.fit\u001b[0;34m(self, Y, T, X, W, sample_weight, freq_weight, sample_var, groups, cache_values, inference)\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, Y, T, \u001b[38;5;241m*\u001b[39m, X\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, W\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, freq_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_var\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    517\u001b[0m         cache_values\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, inference\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;124;03m    Estimate the counterfactual model from data, i.e. estimates functions τ(·,·,·), ∂τ(·,·).\u001b[39;00m\n\u001b[1;32m    520\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;124;03m    self\u001b[39;00m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreq_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m                       \u001b[49m\u001b[43msample_var\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mcache_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m                       \u001b[49m\u001b[43minference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/econml/dml/_rlearner.py:376\u001b[0m, in \u001b[0;36m_RLearner.fit\u001b[0;34m(self, Y, T, X, W, sample_weight, freq_weight, sample_var, groups, cache_values, inference)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;124;03mEstimate the counterfactual model from data, i.e. estimates function :math:`\\\\theta(\\\\cdot)`.\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03mself: _RLearner instance\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;66;03m# Replacing fit from _OrthoLearner, to enforce Z=None and improve the docstring\u001b[39;00m\n\u001b[0;32m--> 376\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m                   \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreq_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_var\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mcache_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m                   \u001b[49m\u001b[43minference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/econml/_cate_estimator.py:130\u001b[0m, in \u001b[0;36mBaseCateEstimator._wrap_fit.<locals>.call\u001b[0;34m(self, Y, T, inference, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m     inference\u001b[38;5;241m.\u001b[39mprefit(\u001b[38;5;28mself\u001b[39m, Y, T, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# call the wrapped fit method\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_postfit(Y, T, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inference \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;66;03m# NOTE: we call inference fit *after* calling the main fit method\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/econml/_ortho_learner.py:650\u001b[0m, in \u001b[0;36m_OrthoLearner.fit\u001b[0;34m(self, Y, T, X, W, Z, sample_weight, freq_weight, sample_var, groups, cache_values, inference, only_final, check_input)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_models_nuisance \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmc_iters \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 650\u001b[0m     nuisances, fitted_models, new_inds, scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_nuisances\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m        \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight_nuisances\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    652\u001b[0m     all_nuisances\u001b[38;5;241m.\u001b[39mappend(nuisances)\n\u001b[1;32m    653\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_models_nuisance\u001b[38;5;241m.\u001b[39mappend(fitted_models)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/econml/_ortho_learner.py:793\u001b[0m, in \u001b[0;36m_OrthoLearner._fit_nuisances\u001b[0;34m(self, Y, T, X, W, Z, sample_weight, groups)\u001b[0m\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    791\u001b[0m         folds \u001b[38;5;241m=\u001b[39m splitter\u001b[38;5;241m.\u001b[39msplit(to_split, strata)\n\u001b[0;32m--> 793\u001b[0m nuisances, fitted_models, fitted_inds, scores \u001b[38;5;241m=\u001b[39m \u001b[43m_crossfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ortho_learner_model_nuisance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m                                                          \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZ\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mZ\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m                                                          \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nuisances, fitted_models, fitted_inds, scores\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/econml/_ortho_learner.py:138\u001b[0m, in \u001b[0;36m_crossfit\u001b[0;34m(model, folds, *args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m folds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# skip crossfitting\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     model_list\u001b[38;5;241m.\u001b[39mappend(clone(model, safe\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[0;32m--> 138\u001b[0m     \u001b[43mmodel_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m     nuisances \u001b[38;5;241m=\u001b[39m model_list[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    140\u001b[0m     scores \u001b[38;5;241m=\u001b[39m model_list[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mscore(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mif\u001b[39;00m calculate_scores \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/econml/dml/_rlearner.py:51\u001b[0m, in \u001b[0;36m_ModelNuisance.fit\u001b[0;34m(self, Y, T, X, W, Z, sample_weight, groups)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, Y, T, X\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, W\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, Z\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m Z \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot accept instrument!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfilter_none_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_y\u001b[38;5;241m.\u001b[39mfit(X, W, Y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfilter_none_kwargs(sample_weight\u001b[38;5;241m=\u001b[39msample_weight, groups\u001b[38;5;241m=\u001b[39mgroups))\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/econml/dml/dml.py:75\u001b[0m, in \u001b[0;36m_FirstStageWrapper.fit\u001b[0;34m(self, X, W, Target, sample_weight, groups)\u001b[0m\n\u001b[1;32m     72\u001b[0m     fit_with_groups(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine(X, W, Target\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]), Target, groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[1;32m     73\u001b[0m                     sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 75\u001b[0m     \u001b[43mfit_with_groups\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_combine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/econml/utilities.py:943\u001b[0m, in \u001b[0;36mfit_with_groups\u001b[0;34m(model, X, y, groups, **kwargs)\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    941\u001b[0m             model\u001b[38;5;241m.\u001b[39mcv \u001b[38;5;241m=\u001b[39m old_cv\n\u001b[0;32m--> 943\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/catboost/core.py:5728\u001b[0m, in \u001b[0;36mCatBoostRegressor.fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5726\u001b[0m _process_synonyms(params)\n\u001b[1;32m   5727\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[0;32m-> 5728\u001b[0m     \u001b[43mCatBoostRegressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_is_compatible_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mloss_function\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X, y, cat_features, text_features, embedding_features, \u001b[38;5;28;01mNone\u001b[39;00m, sample_weight, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, baseline,\n\u001b[1;32m   5731\u001b[0m                  use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description,\n\u001b[1;32m   5732\u001b[0m                  verbose_eval, metric_period, silent, early_stopping_rounds,\n\u001b[1;32m   5733\u001b[0m                  save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/catboost/core.py:5859\u001b[0m, in \u001b[0;36mCatBoostRegressor._check_is_compatible_loss\u001b[0;34m(loss_function)\u001b[0m\n\u001b[1;32m   5857\u001b[0m is_regression \u001b[38;5;241m=\u001b[39m CatBoost\u001b[38;5;241m.\u001b[39m_is_regression_objective(loss_function) \u001b[38;5;129;01mor\u001b[39;00m CatBoost\u001b[38;5;241m.\u001b[39m_is_multiregression_objective(loss_function) \u001b[38;5;129;01mor\u001b[39;00m CatBoost\u001b[38;5;241m.\u001b[39m_is_survivalregression_objective(loss_function)\n\u001b[1;32m   5858\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loss_function, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_regression:\n\u001b[0;32m-> 5859\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid loss_function=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: for regressor use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5860\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSE, MultiRMSE, SurvivalAft, MAE, Quantile, LogLinQuantile, Poisson, MAPE, Lq or custom objective object\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(loss_function))\n",
      "\u001b[0;31mCatBoostError\u001b[0m: Invalid loss_function='Logloss': for regressor use RMSE, MultiRMSE, SurvivalAft, MAE, Quantile, LogLinQuantile, Poisson, MAPE, Lq or custom objective object"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "from econml.dml import LinearDML\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from scipy.stats import logistic\n",
    "\n",
    "MC_N = 1\n",
    "MC_θ = np.zeros((MC_N,4))\n",
    "MC_y = np.zeros((MC_N,4))\n",
    "MC_t = np.zeros((MC_N,4))\n",
    "\n",
    "for j in range(MC_N):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    df = pd.read_csv('/Users/pranjal/Desktop/Causal-Inference/data/wage.csv')\n",
    "    cat = df.select_dtypes('object').columns\n",
    "    df = pd.get_dummies(df, columns = cat, drop_first = True)\n",
    "    outcome = 'lwage'\n",
    "    treatment = 'educ'\n",
    "    #rest = list(df.drop([outcome, treatment], axis = 1).columns)\n",
    "    rest = ['exper','age', 'kidslt6', 'kidsge6']\n",
    "    df = df[[outcome] + [treatment] + rest]\n",
    "    df = df.dropna()\n",
    "    y = df[outcome]\n",
    "    t = df[treatment]\n",
    "    x = df[rest].astype('float')\n",
    "    print(x.shape, t.shape, y.shape)\n",
    "    \n",
    "    # OLS - Full Estimation\n",
    "    model_OLS = sm.OLS(y, sm.add_constant(np.c_[t,x]))\n",
    "    res = model_OLS.fit()\n",
    "    θ_OLS = res.params[1]\n",
    "    # OLS First Stage: Y\n",
    "    model_OLS = sm.OLS(y, sm.add_constant(np.c_[x]))\n",
    "    res_y = model_OLS.fit()\n",
    "    θ_OLS_y = res_y.params[1]    \n",
    "    # Logistic First Stage\n",
    "    clf = LinearRegression().fit(x, t)\n",
    "    \n",
    "    # DML Lasso\n",
    "    model_Lasso = LinearDML(discrete_treatment=False, random_state=1, cv=1)\n",
    "    model_Lasso.fit(y.ravel(), t.ravel(), X=None,W=x)\n",
    "    θ_DMLL = model_Lasso.intercept_\n",
    "    \n",
    "    # DML RF\n",
    "    model_XGB = LinearDML(discrete_treatment=False, cv=1,\n",
    "                          model_y = CatBoostRegressor(iterations=10000,\n",
    "                                                       depth=12,\n",
    "                                                       learning_rate=0.01,\n",
    "                                                       loss_function='RMSE',\n",
    "                                                       verbose=100,\n",
    "                                                       eval_metric=\"R2\",\n",
    "                                                       eval_fraction=0.2),\n",
    "                          model_t = CatBoostRegressor(iterations=10000,\n",
    "                                                       depth=8,\n",
    "                                                       learning_rate=0.01,\n",
    "                                                       loss_function='RMSE',\n",
    "                                                       verbose=1000, \n",
    "                                                       eval_metric=\"R2\",\n",
    "                                                       eval_fraction=0.2))\n",
    "    model_XGB.fit(y.ravel(), t.ravel(), X=None,W=x)\n",
    "    θ_DMLRF = model_XGB.intercept_\n",
    "    \n",
    "    # DML NN - First Stage\n",
    "    model_NN = LinearDML(discrete_treatment=False, cv =1,\n",
    "                         model_y = MLPRegressor(random_state=1,\n",
    "                                                 hidden_layer_sizes=(500,100,50), \n",
    "                                                 batch_size = x.shape[0],\n",
    "                                                 momentum = 0.95, \n",
    "                                                 max_iter=50000, \n",
    "                                                 learning_rate_init=0.01, \n",
    "                                                 verbose=False), \n",
    "                         model_t = CatBoostRegressor(random_state=1,\n",
    "                                                 hidden_layer_sizes=(500,100,50), \n",
    "                                                 batch_size = x.shape[0],\n",
    "                                                 momentum = 0.95, \n",
    "                                                 max_iter=50000, \n",
    "                                                 learning_rate_init=0.01, \n",
    "                                                 verbose=False))\n",
    "    model_NN.fit(y.ravel(), t.ravel(), X=None,W=x)\n",
    "    θ_DMLRF = model_NN.intercept_\n",
    "\n",
    "\n",
    "    MC_θ[j] = [θ_OLS, model_Lasso.intercept_, model_XGB.intercept_, model_NN.intercept_]\n",
    "    MC_y[j] = [res_y.rsquared, np.mean(model_Lasso.nuisance_scores_y), np.mean(model_XGB.nuisance_scores_y),np.mean(model_NN.nuisance_scores_y)]\n",
    "    MC_t[j] = [clf.score(x,t), np.mean(model_Lasso.nuisance_scores_t), np.mean(model_XGB.nuisance_scores_t),np.mean(model_NN.nuisance_scores_t)]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "31aebd79",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+-------+-----------+--------+\n",
      "|       Var        |  OLS  | DML-L | DML-Boost | DML-NN |\n",
      "+------------------+-------+-------+-----------+--------+\n",
      "|      θ_hat       | 0.110 | 0.110 |   0.124   | 0.101  |\n",
      "| First Stage Y R2 | 0.034 | 0.027 |   0.924   | 0.032  |\n",
      "| First Stage D R2 | 0.031 | 0.031 |   0.866   | -0.024 |\n",
      "+------------------+-------+-------+-----------+--------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Var', 'OLS','DML-L','DML-Boost','DML-NN']\n",
    "a = ['θ_hat']+ np.mean(MC_θ, axis = 0).tolist()\n",
    "table.add_row(a)\n",
    "a = ['First Stage Y R2']+ np.mean(MC_y, axis = 0).tolist()\n",
    "table.add_row(a)\n",
    "a = ['First Stage D R2']+ np.mean(MC_t, axis = 0).tolist()\n",
    "table.add_row(a)\n",
    "table.float_format = '0.3'\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b847c801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>lwage</td>      <th>  R-squared:         </th> <td>   0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   3.772</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 09 Dec 2022</td> <th>  Prob (F-statistic):</th>  <td>0.00500</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:20:51</td>     <th>  Log-Likelihood:    </th> <td> -460.60</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   428</td>      <th>  AIC:               </th> <td>   931.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   423</td>      <th>  BIC:               </th> <td>   951.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    1.2752</td> <td>    0.242</td> <td>    5.273</td> <td> 0.000</td> <td>    0.800</td> <td>    1.751</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.0149</td> <td>    0.005</td> <td>    2.957</td> <td> 0.003</td> <td>    0.005</td> <td>    0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.0053</td> <td>    0.006</td> <td>   -0.955</td> <td> 0.340</td> <td>   -0.016</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0006</td> <td>    0.094</td> <td>    0.007</td> <td> 0.995</td> <td>   -0.184</td> <td>    0.185</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0428</td> <td>    0.030</td> <td>   -1.450</td> <td> 0.148</td> <td>   -0.101</td> <td>    0.015</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>50.962</td> <th>  Durbin-Watson:     </th> <td>   1.961</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 145.252</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.553</td> <th>  Prob(JB):          </th> <td>2.88e-32</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.631</td> <th>  Cond. No.          </th> <td>    318.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  lwage   R-squared:                       0.034\n",
       "Model:                            OLS   Adj. R-squared:                  0.025\n",
       "Method:                 Least Squares   F-statistic:                     3.772\n",
       "Date:                Fri, 09 Dec 2022   Prob (F-statistic):            0.00500\n",
       "Time:                        18:20:51   Log-Likelihood:                -460.60\n",
       "No. Observations:                 428   AIC:                             931.2\n",
       "Df Residuals:                     423   BIC:                             951.5\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          1.2752      0.242      5.273      0.000       0.800       1.751\n",
       "x1             0.0149      0.005      2.957      0.003       0.005       0.025\n",
       "x2            -0.0053      0.006     -0.955      0.340      -0.016       0.006\n",
       "x3             0.0006      0.094      0.007      0.995      -0.184       0.185\n",
       "x4            -0.0428      0.030     -1.450      0.148      -0.101       0.015\n",
       "==============================================================================\n",
       "Omnibus:                       50.962   Durbin-Watson:                   1.961\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              145.252\n",
       "Skew:                          -0.553   Prob(JB):                     2.88e-32\n",
       "Kurtosis:                       5.631   Cond. No.                         318.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_y.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "62704fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient Results:  X is None, please call intercept_inference to learn the constant!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>CATE Intercept Results</caption>\n",
       "<tr>\n",
       "         <td></td>        <th>point_estimate</th> <th>stderr</th> <th>zstat</th> <th>pvalue</th> <th>ci_lower</th> <th>ci_upper</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cate_intercept</th>      <td>0.124</td>      <td>0.023</td> <td>5.492</td>   <td>0.0</td>    <td>0.08</td>     <td>0.168</td> \n",
       "</tr>\n",
       "</table><br/><br/><sub>A linear parametric conditional average treatment effect (CATE) model was fitted:<br/>$Y = \\Theta(X)\\cdot T + g(X, W) + \\epsilon$<br/>where for every outcome $i$ and treatment $j$ the CATE $\\Theta_{ij}(X)$ has the form:<br/>$\\Theta_{ij}(X) = X' coef_{ij} + cate\\_intercept_{ij}$<br/>Coefficient Results table portrays the $coef_{ij}$ parameter vector for each outcome $i$ and treatment $j$. Intercept Results table portrays the $cate\\_intercept_{ij}$ parameter.</sub>"
      ],
      "text/plain": [
       "<class 'econml.utilities.Summary'>\n",
       "\"\"\"\n",
       "                       CATE Intercept Results                      \n",
       "===================================================================\n",
       "               point_estimate stderr zstat pvalue ci_lower ci_upper\n",
       "-------------------------------------------------------------------\n",
       "cate_intercept          0.124  0.023 5.492    0.0     0.08    0.168\n",
       "-------------------------------------------------------------------\n",
       "\n",
       "<sub>A linear parametric conditional average treatment effect (CATE) model was fitted:\n",
       "$Y = \\Theta(X)\\cdot T + g(X, W) + \\epsilon$\n",
       "where for every outcome $i$ and treatment $j$ the CATE $\\Theta_{ij}(X)$ has the form:\n",
       "$\\Theta_{ij}(X) = X' coef_{ij} + cate\\_intercept_{ij}$\n",
       "Coefficient Results table portrays the $coef_{ij}$ parameter vector for each outcome $i$ and treatment $j$. Intercept Results table portrays the $cate\\_intercept_{ij}$ parameter.</sub>\n",
       "\"\"\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_XGB.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfabf74c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_cached_values',\n",
       " '_check_fitted_dims',\n",
       " '_check_fitted_dims_w_z',\n",
       " '_check_input_dims',\n",
       " '_d_t',\n",
       " '_d_t_in',\n",
       " '_d_w',\n",
       " '_d_x',\n",
       " '_d_y',\n",
       " '_d_z',\n",
       " '_defer_to_inference',\n",
       " '_expand_treatments',\n",
       " '_fit_final',\n",
       " '_fit_nuisances',\n",
       " '_gen_featurizer',\n",
       " '_gen_model_final',\n",
       " '_gen_model_t',\n",
       " '_gen_model_y',\n",
       " '_gen_ortho_learner_model_final',\n",
       " '_gen_ortho_learner_model_nuisance',\n",
       " '_gen_rlearner_model_final',\n",
       " '_get_inference',\n",
       " '_get_inference_options',\n",
       " '_illegal_refit_inference_methods',\n",
       " '_inference',\n",
       " '_input_names',\n",
       " '_models_nuisance',\n",
       " '_original_treatment_featurizer',\n",
       " '_ortho_learner_model_final',\n",
       " '_ortho_learner_model_nuisance',\n",
       " '_postfit',\n",
       " '_prefit',\n",
       " '_random_state',\n",
       " '_set_input_names',\n",
       " '_set_transformed_treatment_names',\n",
       " '_strata',\n",
       " '_subinds_check_none',\n",
       " '_use_inference_method',\n",
       " '_wrap_fit',\n",
       " 'ate',\n",
       " 'ate_inference',\n",
       " 'ate_interval',\n",
       " 'bias_part_of_coef',\n",
       " 'cate_feature_names',\n",
       " 'cate_output_names',\n",
       " 'cate_treatment_names',\n",
       " 'categories',\n",
       " 'coef_',\n",
       " 'coef__inference',\n",
       " 'coef__interval',\n",
       " 'const_marginal_ate',\n",
       " 'const_marginal_ate_inference',\n",
       " 'const_marginal_ate_interval',\n",
       " 'const_marginal_effect',\n",
       " 'const_marginal_effect_inference',\n",
       " 'const_marginal_effect_interval',\n",
       " 'cv',\n",
       " 'discrete_instrument',\n",
       " 'discrete_treatment',\n",
       " 'dowhy',\n",
       " 'effect',\n",
       " 'effect_inference',\n",
       " 'effect_interval',\n",
       " 'featurizer',\n",
       " 'featurizer_',\n",
       " 'fit',\n",
       " 'fit_cate_intercept',\n",
       " 'fit_cate_intercept_',\n",
       " 'intercept_',\n",
       " 'intercept__inference',\n",
       " 'intercept__interval',\n",
       " 'linear_first_stages',\n",
       " 'marginal_ate',\n",
       " 'marginal_ate_inference',\n",
       " 'marginal_ate_interval',\n",
       " 'marginal_effect',\n",
       " 'marginal_effect_inference',\n",
       " 'marginal_effect_interval',\n",
       " 'mc_agg',\n",
       " 'mc_iters',\n",
       " 'model_cate',\n",
       " 'model_final',\n",
       " 'model_final_',\n",
       " 'model_t',\n",
       " 'model_y',\n",
       " 'models_nuisance_',\n",
       " 'models_t',\n",
       " 'models_y',\n",
       " 'nuisance_scores_',\n",
       " 'nuisance_scores_t',\n",
       " 'nuisance_scores_y',\n",
       " 'original_featurizer',\n",
       " 'ortho_learner_model_final_',\n",
       " 'random_state',\n",
       " 'refit_final',\n",
       " 'residuals_',\n",
       " 'rlearner_model_final_',\n",
       " 'score',\n",
       " 'score_',\n",
       " 'shap_values',\n",
       " 'summary',\n",
       " 'transformer',\n",
       " 'treatment_featurizer',\n",
       " 'z_transformer']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model_XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea37017f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
