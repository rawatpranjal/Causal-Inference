{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f47c8cc",
   "metadata": {},
   "source": [
    "* Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1ddf1ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import econml\n",
    "import numpy as np\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "163a60cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "setting an array element with a sequence. This was supported in some cases where the elements are arrays with a single element. For example `np.array([1, np.array([2])], dtype=int)`. In the future this will raise the same ValueError as `np.array([1, [2]], dtype=int)`.\n",
      "setting an array element with a sequence. This was supported in some cases where the elements are arrays with a single element. For example `np.array([1, np.array([2])], dtype=int)`. In the future this will raise the same ValueError as `np.array([1, [2]], dtype=int)`.\n",
      "setting an array element with a sequence. This was supported in some cases where the elements are arrays with a single element. For example `np.array([1, np.array([2])], dtype=int)`. In the future this will raise the same ValueError as `np.array([1, [2]], dtype=int)`.\n",
      "setting an array element with a sequence. This was supported in some cases where the elements are arrays with a single element. For example `np.array([1, np.array([2])], dtype=int)`. In the future this will raise the same ValueError as `np.array([1, [2]], dtype=int)`.\n",
      "setting an array element with a sequence. This was supported in some cases where the elements are arrays with a single element. For example `np.array([1, np.array([2])], dtype=int)`. In the future this will raise the same ValueError as `np.array([1, [2]], dtype=int)`.\n",
      "setting an array element with a sequence. This was supported in some cases where the elements are arrays with a single element. For example `np.array([1, np.array([2])], dtype=int)`. In the future this will raise the same ValueError as `np.array([1, [2]], dtype=int)`.\n",
      "setting an array element with a sequence. This was supported in some cases where the elements are arrays with a single element. For example `np.array([1, np.array([2])], dtype=int)`. In the future this will raise the same ValueError as `np.array([1, [2]], dtype=int)`.\n",
      "setting an array element with a sequence. This was supported in some cases where the elements are arrays with a single element. For example `np.array([1, np.array([2])], dtype=int)`. In the future this will raise the same ValueError as `np.array([1, [2]], dtype=int)`.\n",
      "setting an array element with a sequence. This was supported in some cases where the elements are arrays with a single element. For example `np.array([1, np.array([2])], dtype=int)`. In the future this will raise the same ValueError as `np.array([1, [2]], dtype=int)`.\n",
      "setting an array element with a sequence. This was supported in some cases where the elements are arrays with a single element. For example `np.array([1, np.array([2])], dtype=int)`. In the future this will raise the same ValueError as `np.array([1, [2]], dtype=int)`.\n",
      "setting an array element with a sequence. This was supported in some cases where the elements are arrays with a single element. For example `np.array([1, np.array([2])], dtype=int)`. In the future this will raise the same ValueError as `np.array([1, [2]], dtype=int)`.\n",
      "setting an array element with a sequence. This was supported in some cases where the elements are arrays with a single element. For example `np.array([1, np.array([2])], dtype=int)`. In the future this will raise the same ValueError as `np.array([1, [2]], dtype=int)`.\n",
      "setting an array element with a sequence. This was supported in some cases where the elements are arrays with a single element. For example `np.array([1, np.array([2])], dtype=int)`. In the future this will raise the same ValueError as `np.array([1, [2]], dtype=int)`.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [151], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# DML RF\u001b[39;00m\n\u001b[1;32m     33\u001b[0m est \u001b[38;5;241m=\u001b[39m LinearDML(discrete_treatment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, model_y \u001b[38;5;241m=\u001b[39m RandomForestRegressor(), model_t \u001b[38;5;241m=\u001b[39m RandomForestRegressor())\n\u001b[0;32m---> 34\u001b[0m \u001b[43mest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mW\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m θ_DMLRF \u001b[38;5;241m=\u001b[39m est\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[1;32m     37\u001b[0m MC_store[j] \u001b[38;5;241m=\u001b[39m [θ_OLS, θ_DMLL, θ_DMLRF]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/econml/dml/dml.py:753\u001b[0m, in \u001b[0;36mLinearDML.fit\u001b[0;34m(self, Y, T, X, W, sample_weight, freq_weight, sample_var, groups, cache_values, inference)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, Y, T, \u001b[38;5;241m*\u001b[39m, X\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, W\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, freq_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_var\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    715\u001b[0m         cache_values\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, inference\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;124;03m    Estimate the counterfactual model from data, i.e. estimates functions τ(·,·,·), ∂τ(·,·).\u001b[39;00m\n\u001b[1;32m    718\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;124;03m    self\u001b[39;00m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 753\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[43m                       \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreq_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_var\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mcache_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    756\u001b[0m \u001b[43m                       \u001b[49m\u001b[43minference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/econml/dml/dml.py:555\u001b[0m, in \u001b[0;36mDML.fit\u001b[0;34m(self, Y, T, X, W, sample_weight, freq_weight, sample_var, groups, cache_values, inference)\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, Y, T, \u001b[38;5;241m*\u001b[39m, X\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, W\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, freq_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_var\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    517\u001b[0m         cache_values\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, inference\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;124;03m    Estimate the counterfactual model from data, i.e. estimates functions τ(·,·,·), ∂τ(·,·).\u001b[39;00m\n\u001b[1;32m    520\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;124;03m    self\u001b[39;00m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreq_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m                       \u001b[49m\u001b[43msample_var\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mcache_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m                       \u001b[49m\u001b[43minference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/econml/dml/_rlearner.py:376\u001b[0m, in \u001b[0;36m_RLearner.fit\u001b[0;34m(self, Y, T, X, W, sample_weight, freq_weight, sample_var, groups, cache_values, inference)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;124;03mEstimate the counterfactual model from data, i.e. estimates function :math:`\\\\theta(\\\\cdot)`.\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03mself: _RLearner instance\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;66;03m# Replacing fit from _OrthoLearner, to enforce Z=None and improve the docstring\u001b[39;00m\n\u001b[0;32m--> 376\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m                   \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreq_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_var\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mcache_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m                   \u001b[49m\u001b[43minference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/econml/_cate_estimator.py:130\u001b[0m, in \u001b[0;36mBaseCateEstimator._wrap_fit.<locals>.call\u001b[0;34m(self, Y, T, inference, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m     inference\u001b[38;5;241m.\u001b[39mprefit(\u001b[38;5;28mself\u001b[39m, Y, T, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# call the wrapped fit method\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_postfit(Y, T, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inference \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;66;03m# NOTE: we call inference fit *after* calling the main fit method\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/econml/_ortho_learner.py:650\u001b[0m, in \u001b[0;36m_OrthoLearner.fit\u001b[0;34m(self, Y, T, X, W, Z, sample_weight, freq_weight, sample_var, groups, cache_values, inference, only_final, check_input)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_models_nuisance \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmc_iters \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 650\u001b[0m     nuisances, fitted_models, new_inds, scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_nuisances\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m        \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight_nuisances\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    652\u001b[0m     all_nuisances\u001b[38;5;241m.\u001b[39mappend(nuisances)\n\u001b[1;32m    653\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_models_nuisance\u001b[38;5;241m.\u001b[39mappend(fitted_models)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/econml/_ortho_learner.py:793\u001b[0m, in \u001b[0;36m_OrthoLearner._fit_nuisances\u001b[0;34m(self, Y, T, X, W, Z, sample_weight, groups)\u001b[0m\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    791\u001b[0m         folds \u001b[38;5;241m=\u001b[39m splitter\u001b[38;5;241m.\u001b[39msplit(to_split, strata)\n\u001b[0;32m--> 793\u001b[0m nuisances, fitted_models, fitted_inds, scores \u001b[38;5;241m=\u001b[39m \u001b[43m_crossfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ortho_learner_model_nuisance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m                                                          \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZ\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mZ\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m                                                          \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nuisances, fitted_models, fitted_inds, scores\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/econml/_ortho_learner.py:168\u001b[0m, in \u001b[0;36m_crossfit\u001b[0;34m(model, folds, *args, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m kwargs_train \u001b[38;5;241m=\u001b[39m {key: var[train_idxs] \u001b[38;5;28;01mfor\u001b[39;00m key, var \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    166\u001b[0m kwargs_test \u001b[38;5;241m=\u001b[39m {key: var[test_idxs] \u001b[38;5;28;01mfor\u001b[39;00m key, var \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m--> 168\u001b[0m \u001b[43mmodel_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m nuisance_temp \u001b[38;5;241m=\u001b[39m model_list[idx]\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;241m*\u001b[39margs_test, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs_test)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(nuisance_temp, \u001b[38;5;28mtuple\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/econml/dml/_rlearner.py:52\u001b[0m, in \u001b[0;36m_ModelNuisance.fit\u001b[0;34m(self, Y, T, X, W, Z, sample_weight, groups)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m Z \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot accept instrument!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_t\u001b[38;5;241m.\u001b[39mfit(X, W, T, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfilter_none_kwargs(sample_weight\u001b[38;5;241m=\u001b[39msample_weight, groups\u001b[38;5;241m=\u001b[39mgroups))\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model_y\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfilter_none_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/econml/dml/dml.py:75\u001b[0m, in \u001b[0;36m_FirstStageWrapper.fit\u001b[0;34m(self, X, W, Target, sample_weight, groups)\u001b[0m\n\u001b[1;32m     72\u001b[0m     fit_with_groups(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine(X, W, Target\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]), Target, groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[1;32m     73\u001b[0m                     sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 75\u001b[0m     \u001b[43mfit_with_groups\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_combine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/econml/utilities.py:943\u001b[0m, in \u001b[0;36mfit_with_groups\u001b[0;34m(model, X, y, groups, **kwargs)\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    941\u001b[0m             model\u001b[38;5;241m.\u001b[39mcv \u001b[38;5;241m=\u001b[39m old_cv\n\u001b[0;32m--> 943\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:476\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    465\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    468\u001b[0m ]\n\u001b[1;32m    470\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 476\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:189\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    187\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 189\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    191\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/tree/_classes.py:1342\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1314\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   1315\u001b[0m \n\u001b[1;32m   1316\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1340\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1342\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1344\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1345\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1346\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1347\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1348\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/tree/_classes.py:458\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    449\u001b[0m         splitter,\n\u001b[1;32m    450\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    456\u001b[0m     )\n\u001b[0;32m--> 458\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Example 1\n",
    "MC_N = 100\n",
    "MC_store = np.zeros((MC_N,3))\n",
    "for j in range(MC_N):\n",
    "    import numpy as np\n",
    "    N = 10000\n",
    "    σ_t = 1\n",
    "    σ_y = 1\n",
    "    σ_x = 1\n",
    "    θ = 0.5 # TRUE ATE\n",
    "    α_t = 0.5\n",
    "    α_y = 0.5\n",
    "    x = np.random.normal(0,σ_x,N)\n",
    "    e_t = np.random.normal(0,σ_t,N)\n",
    "    e_y = np.random.normal(0,σ_y,N)\n",
    "    t = α_t * x + e_t\n",
    "    y = α_y * x + θ * t + e_y\n",
    "    x = x.reshape(-1, 1)\n",
    "    y = y.reshape(-1, 1)\n",
    "    t = t.reshape(-1, 1)\n",
    "\n",
    "    # OLS\n",
    "    mod = sm.OLS(y, np.c_[t,x])\n",
    "    res = mod.fit()\n",
    "    θ_OLS = res.params[0]\n",
    "\n",
    "    # DML Lasso\n",
    "    est = LinearDML(random_state=1)\n",
    "    est.fit(y, t, X=None,W=x)\n",
    "    θ_DMLL = est.intercept_\n",
    "\n",
    "    # DML RF\n",
    "    est = LinearDML(discrete_treatment=False, model_y = RandomForestRegressor(), model_t = RandomForestRegressor())\n",
    "    est.fit(y.ravel(), t.ravel(), X=None,W=x)\n",
    "    θ_DMLRF = est.intercept_\n",
    "    \n",
    "    MC_store[j] = [θ_OLS, θ_DMLL, θ_DMLRF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "14188c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.457\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.457\n",
      "Method:                 Least Squares   F-statistic:                              4202.\n",
      "Date:                Wed, 07 Dec 2022   Prob (F-statistic):                        0.00\n",
      "Time:                        16:07:11   Log-Likelihood:                         -14286.\n",
      "No. Observations:               10000   AIC:                                  2.858e+04\n",
      "Df Residuals:                    9998   BIC:                                  2.859e+04\n",
      "Df Model:                           2                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.5204      0.010     51.111      0.000       0.500       0.540\n",
      "x2             0.5125      0.011     45.723      0.000       0.491       0.534\n",
      "==============================================================================\n",
      "Omnibus:                        0.662   Durbin-Watson:                   1.992\n",
      "Prob(Omnibus):                  0.718   Jarque-Bera (JB):                0.632\n",
      "Skew:                           0.016   Prob(JB):                        0.729\n",
      "Kurtosis:                       3.021   Cond. No.                         1.62\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Multivariate regression\n",
    "import statsmodels.api as sm\n",
    "mod = sm.OLS(y, np.c_[t,x])\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b6c92485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient Results:  X is None, please call intercept_inference to learn the constant!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>CATE Intercept Results</caption>\n",
       "<tr>\n",
       "         <td></td>        <th>point_estimate</th> <th>stderr</th>  <th>zstat</th> <th>pvalue</th> <th>ci_lower</th> <th>ci_upper</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cate_intercept</th>      <td>0.494</td>      <td>0.01</td>  <td>49.837</td>   <td>0.0</td>    <td>0.475</td>    <td>0.514</td> \n",
       "</tr>\n",
       "</table><br/><br/><sub>A linear parametric conditional average treatment effect (CATE) model was fitted:<br/>$Y = \\Theta(X)\\cdot T + g(X, W) + \\epsilon$<br/>where for every outcome $i$ and treatment $j$ the CATE $\\Theta_{ij}(X)$ has the form:<br/>$\\Theta_{ij}(X) = X' coef_{ij} + cate\\_intercept_{ij}$<br/>Coefficient Results table portrays the $coef_{ij}$ parameter vector for each outcome $i$ and treatment $j$. Intercept Results table portrays the $cate\\_intercept_{ij}$ parameter.</sub>"
      ],
      "text/plain": [
       "<class 'econml.utilities.Summary'>\n",
       "\"\"\"\n",
       "                       CATE Intercept Results                       \n",
       "====================================================================\n",
       "               point_estimate stderr zstat  pvalue ci_lower ci_upper\n",
       "--------------------------------------------------------------------\n",
       "cate_intercept          0.494   0.01 49.837    0.0    0.475    0.514\n",
       "--------------------------------------------------------------------\n",
       "\n",
       "<sub>A linear parametric conditional average treatment effect (CATE) model was fitted:\n",
       "$Y = \\Theta(X)\\cdot T + g(X, W) + \\epsilon$\n",
       "where for every outcome $i$ and treatment $j$ the CATE $\\Theta_{ij}(X)$ has the form:\n",
       "$\\Theta_{ij}(X) = X' coef_{ij} + cate\\_intercept_{ij}$\n",
       "Coefficient Results table portrays the $coef_{ij}$ parameter vector for each outcome $i$ and treatment $j$. Intercept Results table portrays the $cate\\_intercept_{ij}$ parameter.</sub>\n",
       "\"\"\""
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DML regression - still yeilds unbiased estimate of ATE \n",
    "from econml.dml import LinearDML\n",
    "est = LinearDML(random_state=1)\n",
    "est.fit(y, t, X=None,W=x)\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcab792",
   "metadata": {},
   "source": [
    "* Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "512d8246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1\n",
    "import numpy as np\n",
    "N = 10000\n",
    "σ_t = 1\n",
    "σ_y = 1\n",
    "σ_x = 1\n",
    "θ = 0.5 # TRUE ATE\n",
    "α_t = 0.5\n",
    "α_y = 0.5\n",
    "x = np.random.normal(0,σ_x,N)\n",
    "e_t = np.random.normal(0,σ_t,N)\n",
    "e_y = np.random.normal(0,σ_y,N)\n",
    "t = np.sqrt(α_t * x+10) + e_t\n",
    "y = np.sqrt(α_y * x+10) + θ * t + e_y\n",
    "x = x.reshape(-1, 1)\n",
    "y = y.reshape(-1, 1)\n",
    "t = t.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "92fd08ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.921\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.921\n",
      "Method:                 Least Squares   F-statistic:                          5.827e+04\n",
      "Date:                Tue, 06 Dec 2022   Prob (F-statistic):                        0.00\n",
      "Time:                        13:45:34   Log-Likelihood:                         -17301.\n",
      "No. Observations:               10000   AIC:                                  3.461e+04\n",
      "Df Residuals:                    9998   BIC:                                  3.462e+04\n",
      "Df Model:                           2                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             1.4066      0.004    341.163      0.000       1.399       1.415\n",
      "x2             0.0040      0.014      0.296      0.767      -0.023       0.031\n",
      "==============================================================================\n",
      "Omnibus:                        1.437   Durbin-Watson:                   1.922\n",
      "Prob(Omnibus):                  0.487   Jarque-Bera (JB):                1.422\n",
      "Skew:                          -0.029   Prob(JB):                        0.491\n",
      "Kurtosis:                       3.008   Cond. No.                         3.30\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Multivariate regression\n",
    "import statsmodels.api as sm\n",
    "mod = sm.OLS(y, np.c_[t,x])\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4cf71117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient Results:  X is None, please call intercept_inference to learn the constant!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>CATE Intercept Results</caption>\n",
       "<tr>\n",
       "         <td></td>        <th>point_estimate</th> <th>stderr</th>  <th>zstat</th> <th>pvalue</th> <th>ci_lower</th> <th>ci_upper</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cate_intercept</th>      <td>0.521</td>      <td>0.01</td>  <td>51.168</td>   <td>0.0</td>    <td>0.501</td>    <td>0.541</td> \n",
       "</tr>\n",
       "</table><br/><br/><sub>A linear parametric conditional average treatment effect (CATE) model was fitted:<br/>$Y = \\Theta(X)\\cdot T + g(X, W) + \\epsilon$<br/>where for every outcome $i$ and treatment $j$ the CATE $\\Theta_{ij}(X)$ has the form:<br/>$\\Theta_{ij}(X) = X' coef_{ij} + cate\\_intercept_{ij}$<br/>Coefficient Results table portrays the $coef_{ij}$ parameter vector for each outcome $i$ and treatment $j$. Intercept Results table portrays the $cate\\_intercept_{ij}$ parameter.</sub>"
      ],
      "text/plain": [
       "<class 'econml.utilities.Summary'>\n",
       "\"\"\"\n",
       "                       CATE Intercept Results                       \n",
       "====================================================================\n",
       "               point_estimate stderr zstat  pvalue ci_lower ci_upper\n",
       "--------------------------------------------------------------------\n",
       "cate_intercept          0.521   0.01 51.168    0.0    0.501    0.541\n",
       "--------------------------------------------------------------------\n",
       "\n",
       "<sub>A linear parametric conditional average treatment effect (CATE) model was fitted:\n",
       "$Y = \\Theta(X)\\cdot T + g(X, W) + \\epsilon$\n",
       "where for every outcome $i$ and treatment $j$ the CATE $\\Theta_{ij}(X)$ has the form:\n",
       "$\\Theta_{ij}(X) = X' coef_{ij} + cate\\_intercept_{ij}$\n",
       "Coefficient Results table portrays the $coef_{ij}$ parameter vector for each outcome $i$ and treatment $j$. Intercept Results table portrays the $cate\\_intercept_{ij}$ parameter.</sub>\n",
       "\"\"\""
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DML regression - still yeilds unbiased estimate of ATE \n",
    "from econml.dml import LinearDML\n",
    "est = LinearDML(random_state=1)\n",
    "est.fit(y, t, X=None,W=x)\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e3500106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.52078988]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292b674c",
   "metadata": {},
   "source": [
    "* Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e34695ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1\n",
    "import numpy as np\n",
    "N = 10000\n",
    "σ_t = 1\n",
    "σ_y = 1\n",
    "σ_x = 1\n",
    "θ = 0.5 # TRUE ATE\n",
    "α_t = 0.5\n",
    "α_y = 0.5\n",
    "x = np.random.normal(0,σ_x,N)\n",
    "e_t = np.random.normal(0,σ_t,N)\n",
    "e_y = np.random.normal(0,σ_y,N)\n",
    "t = np.exp(α_t * x) + e_t\n",
    "y = np.exp(α_y * x) + θ * t + e_y\n",
    "x = x.reshape(-1, 1)\n",
    "y = y.reshape(-1, 1)\n",
    "t = t.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "84d28b47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.693\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.693\n",
      "Method:                 Least Squares   F-statistic:                          1.130e+04\n",
      "Date:                Tue, 06 Dec 2022   Prob (F-statistic):                        0.00\n",
      "Time:                        13:45:56   Log-Likelihood:                         -16331.\n",
      "No. Observations:               10000   AIC:                                  3.267e+04\n",
      "Df Residuals:                    9998   BIC:                                  3.268e+04\n",
      "Df Model:                           2                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             1.0684      0.008    132.365      0.000       1.053       1.084\n",
      "x2             0.2592      0.013     19.603      0.000       0.233       0.285\n",
      "==============================================================================\n",
      "Omnibus:                        1.003   Durbin-Watson:                   1.674\n",
      "Prob(Omnibus):                  0.606   Jarque-Bera (JB):                1.026\n",
      "Skew:                           0.008   Prob(JB):                        0.599\n",
      "Kurtosis:                       2.953   Cond. No.                         1.87\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Multivariate regression\n",
    "import statsmodels.api as sm\n",
    "mod = sm.OLS(y, np.c_[t,x])\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "54ee8550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient Results:  X is None, please call intercept_inference to learn the constant!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>CATE Intercept Results</caption>\n",
       "<tr>\n",
       "         <td></td>        <th>point_estimate</th> <th>stderr</th>  <th>zstat</th> <th>pvalue</th> <th>ci_lower</th> <th>ci_upper</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cate_intercept</th>      <td>0.551</td>      <td>0.01</td>  <td>54.585</td>   <td>0.0</td>    <td>0.531</td>    <td>0.57</td>  \n",
       "</tr>\n",
       "</table><br/><br/><sub>A linear parametric conditional average treatment effect (CATE) model was fitted:<br/>$Y = \\Theta(X)\\cdot T + g(X, W) + \\epsilon$<br/>where for every outcome $i$ and treatment $j$ the CATE $\\Theta_{ij}(X)$ has the form:<br/>$\\Theta_{ij}(X) = X' coef_{ij} + cate\\_intercept_{ij}$<br/>Coefficient Results table portrays the $coef_{ij}$ parameter vector for each outcome $i$ and treatment $j$. Intercept Results table portrays the $cate\\_intercept_{ij}$ parameter.</sub>"
      ],
      "text/plain": [
       "<class 'econml.utilities.Summary'>\n",
       "\"\"\"\n",
       "                       CATE Intercept Results                       \n",
       "====================================================================\n",
       "               point_estimate stderr zstat  pvalue ci_lower ci_upper\n",
       "--------------------------------------------------------------------\n",
       "cate_intercept          0.551   0.01 54.585    0.0    0.531     0.57\n",
       "--------------------------------------------------------------------\n",
       "\n",
       "<sub>A linear parametric conditional average treatment effect (CATE) model was fitted:\n",
       "$Y = \\Theta(X)\\cdot T + g(X, W) + \\epsilon$\n",
       "where for every outcome $i$ and treatment $j$ the CATE $\\Theta_{ij}(X)$ has the form:\n",
       "$\\Theta_{ij}(X) = X' coef_{ij} + cate\\_intercept_{ij}$\n",
       "Coefficient Results table portrays the $coef_{ij}$ parameter vector for each outcome $i$ and treatment $j$. Intercept Results table portrays the $cate\\_intercept_{ij}$ parameter.</sub>\n",
       "\"\"\""
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DML regression - still yeilds unbiased estimate of ATE \n",
    "from econml.dml import LinearDML\n",
    "est = LinearDML(random_state=1)\n",
    "est.fit(y, t, X=None,W=x)\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "33cd5f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient Results:  X is None, please call intercept_inference to learn the constant!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>CATE Intercept Results</caption>\n",
       "<tr>\n",
       "         <td></td>        <th>point_estimate</th> <th>stderr</th>  <th>zstat</th> <th>pvalue</th> <th>ci_lower</th> <th>ci_upper</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cate_intercept</th>      <td>0.49</td>       <td>0.01</td>  <td>48.824</td>   <td>0.0</td>    <td>0.47</td>     <td>0.51</td>  \n",
       "</tr>\n",
       "</table><br/><br/><sub>A linear parametric conditional average treatment effect (CATE) model was fitted:<br/>$Y = \\Theta(X)\\cdot T + g(X, W) + \\epsilon$<br/>where for every outcome $i$ and treatment $j$ the CATE $\\Theta_{ij}(X)$ has the form:<br/>$\\Theta_{ij}(X) = X' coef_{ij} + cate\\_intercept_{ij}$<br/>Coefficient Results table portrays the $coef_{ij}$ parameter vector for each outcome $i$ and treatment $j$. Intercept Results table portrays the $cate\\_intercept_{ij}$ parameter.</sub>"
      ],
      "text/plain": [
       "<class 'econml.utilities.Summary'>\n",
       "\"\"\"\n",
       "                       CATE Intercept Results                       \n",
       "====================================================================\n",
       "               point_estimate stderr zstat  pvalue ci_lower ci_upper\n",
       "--------------------------------------------------------------------\n",
       "cate_intercept           0.49   0.01 48.824    0.0     0.47     0.51\n",
       "--------------------------------------------------------------------\n",
       "\n",
       "<sub>A linear parametric conditional average treatment effect (CATE) model was fitted:\n",
       "$Y = \\Theta(X)\\cdot T + g(X, W) + \\epsilon$\n",
       "where for every outcome $i$ and treatment $j$ the CATE $\\Theta_{ij}(X)$ has the form:\n",
       "$\\Theta_{ij}(X) = X' coef_{ij} + cate\\_intercept_{ij}$\n",
       "Coefficient Results table portrays the $coef_{ij}$ parameter vector for each outcome $i$ and treatment $j$. Intercept Results table portrays the $cate\\_intercept_{ij}$ parameter.</sub>\n",
       "\"\"\""
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DML regression - still yeilds unbiased estimate of ATE \n",
    "from econml.dml import LinearDML\n",
    "est = LinearDML(random_state=1)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "est = LinearDML(discrete_treatment=False, model_y = RandomForestRegressor(), model_t = RandomForestRegressor())\n",
    "est.fit(y.ravel(), t.ravel(), X=None,W=x)\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455a81b5",
   "metadata": {},
   "source": [
    "* Example 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "eb91afe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1\n",
    "import numpy as np\n",
    "N = 10000\n",
    "K = 50\n",
    "σ_t = 1\n",
    "σ_y = 1\n",
    "σ_x = 1\n",
    "θ = 0.5 # TRUE ATE\n",
    "α_t = np.random.normal(1,0.1,K)\n",
    "α_y = np.random.normal(1,0.1,K)\n",
    "x = np.random.normal(0,σ_x,(N,K))\n",
    "e_t = np.random.normal(0,σ_t,N)\n",
    "e_y = np.random.normal(0,σ_y,N)\n",
    "t = np.exp(np.dot(α_t,x.T)/100) + e_t\n",
    "y = np.exp(np.dot(α_y,x.T)/100) + θ * t + e_y\n",
    "#x = x.reshape(-1, 1)\n",
    "y = y.reshape(-1, 1)\n",
    "t = t.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f657d10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.577\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.575\n",
      "Method:                 Least Squares   F-statistic:                              266.0\n",
      "Date:                Tue, 06 Dec 2022   Prob (F-statistic):                        0.00\n",
      "Time:                        14:04:34   Log-Likelihood:                         -16207.\n",
      "No. Observations:               10000   AIC:                                  3.252e+04\n",
      "Df Residuals:                    9949   BIC:                                  3.288e+04\n",
      "Df Model:                          51                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             1.0102      0.009    115.879      0.000       0.993       1.027\n",
      "x2             0.0019      0.012      0.158      0.874      -0.022       0.026\n",
      "x3            -0.0151      0.012     -1.230      0.219      -0.039       0.009\n",
      "x4            -0.0021      0.012     -0.171      0.864      -0.027       0.022\n",
      "x5            -0.0084      0.012     -0.686      0.493      -0.032       0.016\n",
      "x6            -0.0106      0.012     -0.859      0.390      -0.035       0.014\n",
      "x7             0.0187      0.012      1.514      0.130      -0.006       0.043\n",
      "x8            -0.0027      0.012     -0.222      0.824      -0.026       0.021\n",
      "x9             0.0007      0.012      0.060      0.953      -0.023       0.025\n",
      "x10            0.0107      0.012      0.868      0.385      -0.013       0.035\n",
      "x11            0.0115      0.012      0.941      0.347      -0.012       0.036\n",
      "x12           -0.0095      0.012     -0.781      0.435      -0.034       0.014\n",
      "x13           -0.0113      0.012     -0.918      0.359      -0.035       0.013\n",
      "x14           -0.0136      0.012     -1.090      0.276      -0.038       0.011\n",
      "x15           -0.0117      0.012     -0.954      0.340      -0.036       0.012\n",
      "x16            0.0167      0.012      1.363      0.173      -0.007       0.041\n",
      "x17            0.0095      0.012      0.779      0.436      -0.014       0.033\n",
      "x18            0.0081      0.012      0.651      0.515      -0.016       0.032\n",
      "x19            0.0171      0.012      1.381      0.167      -0.007       0.041\n",
      "x20            0.0106      0.012      0.857      0.391      -0.014       0.035\n",
      "x21            0.0014      0.012      0.114      0.909      -0.023       0.026\n",
      "x22            0.0131      0.012      1.068      0.286      -0.011       0.037\n",
      "x23            0.0029      0.012      0.235      0.814      -0.021       0.027\n",
      "x24            0.0112      0.012      0.899      0.369      -0.013       0.036\n",
      "x25            0.0088      0.012      0.713      0.476      -0.015       0.033\n",
      "x26            0.0102      0.012      0.828      0.408      -0.014       0.034\n",
      "x27           -0.0037      0.012     -0.301      0.764      -0.028       0.021\n",
      "x28           -0.0195      0.012     -1.584      0.113      -0.044       0.005\n",
      "x29            0.0072      0.012      0.587      0.557      -0.017       0.031\n",
      "x30            0.0093      0.012      0.770      0.441      -0.014       0.033\n",
      "x31            0.0093      0.012      0.753      0.451      -0.015       0.033\n",
      "x32           -0.0091      0.012     -0.743      0.458      -0.033       0.015\n",
      "x33            0.0080      0.012      0.647      0.518      -0.016       0.032\n",
      "x34           -0.0059      0.012     -0.475      0.635      -0.030       0.018\n",
      "x35            0.0176      0.012      1.434      0.152      -0.006       0.042\n",
      "x36           -0.0064      0.012     -0.520      0.603      -0.030       0.018\n",
      "x37           -0.0096      0.012     -0.777      0.437      -0.034       0.015\n",
      "x38            0.0017      0.012      0.140      0.889      -0.022       0.026\n",
      "x39            0.0154      0.012      1.242      0.214      -0.009       0.040\n",
      "x40            0.0162      0.012      1.318      0.188      -0.008       0.040\n",
      "x41           -0.0201      0.012     -1.630      0.103      -0.044       0.004\n",
      "x42            0.0049      0.012      0.403      0.687      -0.019       0.029\n",
      "x43            0.0184      0.012      1.492      0.136      -0.006       0.043\n",
      "x44            0.0143      0.012      1.157      0.247      -0.010       0.039\n",
      "x45           -0.0084      0.012     -0.682      0.495      -0.033       0.016\n",
      "x46            0.0063      0.012      0.511      0.610      -0.018       0.030\n",
      "x47            0.0027      0.012      0.218      0.828      -0.021       0.027\n",
      "x48           -0.0039      0.012     -0.316      0.752      -0.028       0.020\n",
      "x49            0.0091      0.012      0.737      0.461      -0.015       0.033\n",
      "x50            0.0214      0.012      1.745      0.081      -0.003       0.045\n",
      "x51            0.0155      0.012      1.256      0.209      -0.009       0.040\n",
      "==============================================================================\n",
      "Omnibus:                        0.784   Durbin-Watson:                   1.673\n",
      "Prob(Omnibus):                  0.676   Jarque-Bera (JB):                0.815\n",
      "Skew:                           0.010   Prob(JB):                        0.665\n",
      "Kurtosis:                       2.961   Cond. No.                         1.51\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Multivariate regression\n",
    "import statsmodels.api as sm\n",
    "mod = sm.OLS(y, np.c_[t,x])\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d2f9d2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient Results:  X is None, please call intercept_inference to learn the constant!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>CATE Intercept Results</caption>\n",
       "<tr>\n",
       "         <td></td>        <th>point_estimate</th> <th>stderr</th>  <th>zstat</th> <th>pvalue</th> <th>ci_lower</th> <th>ci_upper</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cate_intercept</th>      <td>0.51</td>       <td>0.01</td>  <td>50.784</td>   <td>0.0</td>    <td>0.49</td>     <td>0.53</td>  \n",
       "</tr>\n",
       "</table><br/><br/><sub>A linear parametric conditional average treatment effect (CATE) model was fitted:<br/>$Y = \\Theta(X)\\cdot T + g(X, W) + \\epsilon$<br/>where for every outcome $i$ and treatment $j$ the CATE $\\Theta_{ij}(X)$ has the form:<br/>$\\Theta_{ij}(X) = X' coef_{ij} + cate\\_intercept_{ij}$<br/>Coefficient Results table portrays the $coef_{ij}$ parameter vector for each outcome $i$ and treatment $j$. Intercept Results table portrays the $cate\\_intercept_{ij}$ parameter.</sub>"
      ],
      "text/plain": [
       "<class 'econml.utilities.Summary'>\n",
       "\"\"\"\n",
       "                       CATE Intercept Results                       \n",
       "====================================================================\n",
       "               point_estimate stderr zstat  pvalue ci_lower ci_upper\n",
       "--------------------------------------------------------------------\n",
       "cate_intercept           0.51   0.01 50.784    0.0     0.49     0.53\n",
       "--------------------------------------------------------------------\n",
       "\n",
       "<sub>A linear parametric conditional average treatment effect (CATE) model was fitted:\n",
       "$Y = \\Theta(X)\\cdot T + g(X, W) + \\epsilon$\n",
       "where for every outcome $i$ and treatment $j$ the CATE $\\Theta_{ij}(X)$ has the form:\n",
       "$\\Theta_{ij}(X) = X' coef_{ij} + cate\\_intercept_{ij}$\n",
       "Coefficient Results table portrays the $coef_{ij}$ parameter vector for each outcome $i$ and treatment $j$. Intercept Results table portrays the $cate\\_intercept_{ij}$ parameter.</sub>\n",
       "\"\"\""
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DML regression - still yeilds unbiased estimate of ATE \n",
    "from econml.dml import LinearDML\n",
    "est = LinearDML(random_state=1)\n",
    "est.fit(y, t, X=None,W=x)\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d51d7da",
   "metadata": {},
   "source": [
    "* Example 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "377883f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1\n",
    "import numpy as np\n",
    "N = 10000\n",
    "K = 500\n",
    "σ_t = 1\n",
    "σ_y = 1\n",
    "σ_x = 1\n",
    "θ = 0.5 # TRUE ATE\n",
    "α_t = np.random.normal(1,0.1,K)\n",
    "α_y = np.random.normal(1,0.1,K)\n",
    "x = np.random.normal(0,σ_x,(N,K))\n",
    "e_t = np.random.normal(0,σ_t,N)\n",
    "e_y = np.random.normal(0,σ_y,N)\n",
    "t = np.exp(np.dot(α_t,x.T)/100) + e_t\n",
    "y = np.exp(np.dot(α_y,x.T)/100) + θ * t + e_y\n",
    "#x = x.reshape(-1, 1)\n",
    "y = y.reshape(-1, 1)\n",
    "t = t.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "394f285f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.605\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.585\n",
      "Method:                 Least Squares   F-statistic:                              29.08\n",
      "Date:                Tue, 06 Dec 2022   Prob (F-statistic):                        0.00\n",
      "Time:                        14:05:41   Log-Likelihood:                         -16123.\n",
      "No. Observations:               10000   AIC:                                  3.325e+04\n",
      "Df Residuals:                    9499   BIC:                                  3.686e+04\n",
      "Df Model:                         501                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             1.0001      0.009    111.259      0.000       0.983       1.018\n",
      "x2             0.0145      0.013      1.131      0.258      -0.011       0.040\n",
      "x3            -0.0060      0.013     -0.470      0.639      -0.031       0.019\n",
      "x4            -0.0054      0.013     -0.425      0.671      -0.030       0.020\n",
      "x5            -0.0080      0.013     -0.631      0.528      -0.033       0.017\n",
      "x6             0.0026      0.013      0.205      0.838      -0.022       0.027\n",
      "x7             0.0221      0.013      1.741      0.082      -0.003       0.047\n",
      "x8             0.0213      0.013      1.654      0.098      -0.004       0.047\n",
      "x9            -0.0110      0.013     -0.868      0.385      -0.036       0.014\n",
      "x10           -0.0059      0.013     -0.468      0.640      -0.031       0.019\n",
      "x11           -0.0180      0.013     -1.405      0.160      -0.043       0.007\n",
      "x12            0.0135      0.013      1.061      0.289      -0.011       0.038\n",
      "x13            0.0003      0.013      0.023      0.982      -0.025       0.026\n",
      "x14           -0.0012      0.013     -0.094      0.925      -0.026       0.024\n",
      "x15           -0.0012      0.013     -0.095      0.924      -0.026       0.024\n",
      "x16            0.0285      0.013      2.219      0.027       0.003       0.054\n",
      "x17            0.0104      0.013      0.815      0.415      -0.015       0.036\n",
      "x18           -0.0064      0.013     -0.502      0.616      -0.031       0.019\n",
      "x19           -0.0027      0.013     -0.206      0.837      -0.028       0.023\n",
      "x20            0.0030      0.013      0.235      0.814      -0.022       0.028\n",
      "x21           -0.0156      0.013     -1.224      0.221      -0.041       0.009\n",
      "x22            0.0158      0.013      1.239      0.215      -0.009       0.041\n",
      "x23           -0.0136      0.013     -1.060      0.289      -0.039       0.012\n",
      "x24           -0.0217      0.013     -1.696      0.090      -0.047       0.003\n",
      "x25            0.0211      0.013      1.625      0.104      -0.004       0.046\n",
      "x26           -0.0059      0.013     -0.468      0.640      -0.031       0.019\n",
      "x27            0.0136      0.013      1.072      0.284      -0.011       0.038\n",
      "x28            0.0282      0.013      2.213      0.027       0.003       0.053\n",
      "x29            0.0013      0.013      0.101      0.919      -0.024       0.026\n",
      "x30            0.0059      0.013      0.461      0.645      -0.019       0.031\n",
      "x31            0.0122      0.013      0.951      0.341      -0.013       0.037\n",
      "x32           -0.0116      0.013     -0.918      0.359      -0.036       0.013\n",
      "x33            0.0007      0.013      0.052      0.959      -0.025       0.026\n",
      "x34            0.0092      0.013      0.723      0.470      -0.016       0.034\n",
      "x35            0.0245      0.013      1.928      0.054      -0.000       0.049\n",
      "x36           -0.0030      0.013     -0.232      0.816      -0.028       0.022\n",
      "x37           -0.0077      0.013     -0.606      0.545      -0.033       0.017\n",
      "x38            0.0136      0.013      1.074      0.283      -0.011       0.038\n",
      "x39            0.0099      0.013      0.767      0.443      -0.015       0.035\n",
      "x40            0.0011      0.013      0.088      0.930      -0.024       0.026\n",
      "x41           -0.0131      0.013     -1.020      0.308      -0.038       0.012\n",
      "x42            0.0196      0.013      1.522      0.128      -0.006       0.045\n",
      "x43           -0.0094      0.013     -0.735      0.463      -0.035       0.016\n",
      "x44            0.0081      0.013      0.640      0.522      -0.017       0.033\n",
      "x45           -0.0078      0.013     -0.616      0.538      -0.033       0.017\n",
      "x46            0.0026      0.013      0.205      0.838      -0.022       0.028\n",
      "x47            0.0221      0.013      1.720      0.086      -0.003       0.047\n",
      "x48            0.0094      0.013      0.731      0.465      -0.016       0.035\n",
      "x49            0.0127      0.013      1.003      0.316      -0.012       0.037\n",
      "x50            0.0299      0.013      2.323      0.020       0.005       0.055\n",
      "x51            0.0383      0.013      2.978      0.003       0.013       0.064\n",
      "x52            0.0062      0.013      0.482      0.630      -0.019       0.031\n",
      "x53            0.0022      0.013      0.176      0.861      -0.023       0.027\n",
      "x54            0.0026      0.013      0.205      0.838      -0.023       0.028\n",
      "x55           -0.0064      0.013     -0.503      0.615      -0.031       0.019\n",
      "x56            0.0026      0.013      0.197      0.844      -0.023       0.028\n",
      "x57            0.0118      0.013      0.928      0.354      -0.013       0.037\n",
      "x58            0.0064      0.013      0.502      0.616      -0.018       0.031\n",
      "x59            0.0103      0.013      0.802      0.423      -0.015       0.035\n",
      "x60           -0.0141      0.013     -1.088      0.276      -0.039       0.011\n",
      "x61            0.0154      0.013      1.188      0.235      -0.010       0.041\n",
      "x62            0.0125      0.013      0.980      0.327      -0.013       0.038\n",
      "x63            0.0230      0.013      1.802      0.072      -0.002       0.048\n",
      "x64           -0.0058      0.013     -0.457      0.648      -0.031       0.019\n",
      "x65           -0.0027      0.013     -0.207      0.836      -0.028       0.023\n",
      "x66            0.0041      0.013      0.322      0.747      -0.021       0.029\n",
      "x67            0.0182      0.013      1.439      0.150      -0.007       0.043\n",
      "x68            0.0110      0.013      0.866      0.386      -0.014       0.036\n",
      "x69            0.0268      0.013      2.061      0.039       0.001       0.052\n",
      "x70           -0.0011      0.013     -0.081      0.935      -0.026       0.024\n",
      "x71           -0.0071      0.013     -0.559      0.576      -0.032       0.018\n",
      "x72            0.0147      0.013      1.166      0.244      -0.010       0.039\n",
      "x73           -0.0087      0.013     -0.676      0.499      -0.034       0.017\n",
      "x74            0.0202      0.013      1.586      0.113      -0.005       0.045\n",
      "x75           -0.0020      0.013     -0.152      0.879      -0.027       0.023\n",
      "x76            0.0089      0.013      0.698      0.485      -0.016       0.034\n",
      "x77           -0.0012      0.013     -0.090      0.928      -0.026       0.024\n",
      "x78            0.0038      0.013      0.298      0.766      -0.021       0.029\n",
      "x79            0.0267      0.013      2.097      0.036       0.002       0.052\n",
      "x80            0.0202      0.013      1.586      0.113      -0.005       0.045\n",
      "x81            0.0083      0.013      0.647      0.518      -0.017       0.033\n",
      "x82           -0.0039      0.013     -0.306      0.760      -0.029       0.021\n",
      "x83            0.0076      0.013      0.595      0.552      -0.017       0.033\n",
      "x84           -0.0100      0.013     -0.785      0.432      -0.035       0.015\n",
      "x85            0.0028      0.013      0.220      0.826      -0.022       0.028\n",
      "x86            0.0013      0.013      0.102      0.919      -0.024       0.026\n",
      "x87        -3.378e-05      0.013     -0.003      0.998      -0.025       0.025\n",
      "x88            0.0130      0.013      1.028      0.304      -0.012       0.038\n",
      "x89           -0.0039      0.013     -0.303      0.762      -0.029       0.021\n",
      "x90            0.0145      0.013      1.128      0.259      -0.011       0.040\n",
      "x91           -0.0194      0.013     -1.514      0.130      -0.044       0.006\n",
      "x92            0.0004      0.013      0.028      0.978      -0.025       0.025\n",
      "x93           -0.0122      0.013     -0.958      0.338      -0.037       0.013\n",
      "x94            0.0127      0.013      0.994      0.320      -0.012       0.038\n",
      "x95           -0.0029      0.013     -0.225      0.822      -0.028       0.022\n",
      "x96            0.0084      0.013      0.660      0.509      -0.017       0.033\n",
      "x97            0.0306      0.013      2.373      0.018       0.005       0.056\n",
      "x98            0.0051      0.013      0.398      0.690      -0.020       0.030\n",
      "x99           -0.0063      0.013     -0.498      0.619      -0.031       0.018\n",
      "x100          -0.0223      0.013     -1.748      0.081      -0.047       0.003\n",
      "x101          -0.0057      0.013     -0.448      0.654      -0.031       0.019\n",
      "x102           0.0146      0.013      1.145      0.252      -0.010       0.040\n",
      "x103           0.0008      0.013      0.065      0.948      -0.024       0.026\n",
      "x104          -0.0136      0.013     -1.066      0.286      -0.039       0.011\n",
      "x105           0.0113      0.013      0.886      0.376      -0.014       0.036\n",
      "x106           0.0054      0.013      0.421      0.674      -0.020       0.031\n",
      "x107           0.0218      0.013      1.728      0.084      -0.003       0.046\n",
      "x108          -0.0013      0.013     -0.099      0.921      -0.026       0.024\n",
      "x109           0.0148      0.013      1.168      0.243      -0.010       0.040\n",
      "x110           0.0019      0.013      0.146      0.884      -0.023       0.027\n",
      "x111           0.0004      0.013      0.029      0.977      -0.024       0.025\n",
      "x112           0.0209      0.013      1.634      0.102      -0.004       0.046\n",
      "x113          -0.0034      0.013     -0.264      0.792      -0.028       0.022\n",
      "x114          -0.0070      0.013     -0.542      0.588      -0.032       0.018\n",
      "x115           0.0320      0.013      2.534      0.011       0.007       0.057\n",
      "x116           0.0271      0.013      2.128      0.033       0.002       0.052\n",
      "x117           0.0221      0.013      1.737      0.083      -0.003       0.047\n",
      "x118           0.0096      0.013      0.752      0.452      -0.015       0.035\n",
      "x119           0.0169      0.013      1.307      0.191      -0.008       0.042\n",
      "x120          -0.0093      0.013     -0.719      0.472      -0.035       0.016\n",
      "x121           0.0189      0.013      1.469      0.142      -0.006       0.044\n",
      "x122           0.0237      0.013      1.863      0.063      -0.001       0.049\n",
      "x123          -0.0263      0.013     -2.067      0.039      -0.051      -0.001\n",
      "x124          -0.0093      0.013     -0.727      0.467      -0.034       0.016\n",
      "x125          -0.0044      0.013     -0.345      0.730      -0.030       0.021\n",
      "x126           0.0154      0.013      1.219      0.223      -0.009       0.040\n",
      "x127           0.0021      0.013      0.163      0.871      -0.023       0.027\n",
      "x128          -0.0125      0.013     -0.976      0.329      -0.038       0.013\n",
      "x129           0.0253      0.013      1.991      0.047       0.000       0.050\n",
      "x130          -0.0032      0.013     -0.254      0.799      -0.028       0.022\n",
      "x131           0.0133      0.013      1.049      0.294      -0.012       0.038\n",
      "x132           0.0230      0.013      1.807      0.071      -0.002       0.048\n",
      "x133           0.0070      0.013      0.544      0.586      -0.018       0.032\n",
      "x134           0.0108      0.013      0.845      0.398      -0.014       0.036\n",
      "x135           0.0157      0.013      1.217      0.224      -0.010       0.041\n",
      "x136           0.0065      0.013      0.506      0.613      -0.019       0.032\n",
      "x137           0.0161      0.013      1.246      0.213      -0.009       0.042\n",
      "x138           0.0223      0.013      1.778      0.075      -0.002       0.047\n",
      "x139           0.0028      0.013      0.216      0.829      -0.022       0.028\n",
      "x140           0.0025      0.013      0.197      0.844      -0.022       0.027\n",
      "x141           0.0136      0.013      1.072      0.284      -0.011       0.038\n",
      "x142          -0.0101      0.013     -0.787      0.431      -0.035       0.015\n",
      "x143           0.0081      0.013      0.632      0.527      -0.017       0.033\n",
      "x144           0.0039      0.013      0.301      0.763      -0.021       0.029\n",
      "x145           0.0059      0.013      0.458      0.647      -0.019       0.031\n",
      "x146           0.0195      0.013      1.522      0.128      -0.006       0.045\n",
      "x147           0.0121      0.013      0.941      0.347      -0.013       0.037\n",
      "x148           0.0145      0.013      1.138      0.255      -0.010       0.040\n",
      "x149           0.0317      0.013      2.487      0.013       0.007       0.057\n",
      "x150           0.0281      0.013      2.195      0.028       0.003       0.053\n",
      "x151           0.0092      0.013      0.720      0.471      -0.016       0.034\n",
      "x152           0.0048      0.013      0.377      0.706      -0.020       0.030\n",
      "x153           0.0232      0.013      1.814      0.070      -0.002       0.048\n",
      "x154           0.0269      0.013      2.107      0.035       0.002       0.052\n",
      "x155           0.0114      0.013      0.896      0.370      -0.014       0.036\n",
      "x156           0.0224      0.013      1.729      0.084      -0.003       0.048\n",
      "x157           0.0149      0.013      1.175      0.240      -0.010       0.040\n",
      "x158           0.0159      0.013      1.257      0.209      -0.009       0.041\n",
      "x159           0.0135      0.013      1.070      0.285      -0.011       0.038\n",
      "x160           0.0003      0.013      0.025      0.980      -0.025       0.025\n",
      "x161          -0.0123      0.013     -0.972      0.331      -0.037       0.012\n",
      "x162           0.0238      0.013      1.852      0.064      -0.001       0.049\n",
      "x163          -0.0182      0.013     -1.414      0.158      -0.044       0.007\n",
      "x164           0.0151      0.013      1.173      0.241      -0.010       0.040\n",
      "x165           0.0060      0.013      0.463      0.644      -0.019       0.032\n",
      "x166          -0.0121      0.013     -0.950      0.342      -0.037       0.013\n",
      "x167           0.0037      0.013      0.292      0.770      -0.021       0.029\n",
      "x168           0.0050      0.013      0.391      0.696      -0.020       0.030\n",
      "x169           0.0020      0.013      0.158      0.874      -0.023       0.027\n",
      "x170           0.0034      0.013      0.266      0.790      -0.022       0.029\n",
      "x171           0.0233      0.013      1.841      0.066      -0.002       0.048\n",
      "x172           0.0070      0.013      0.546      0.585      -0.018       0.032\n",
      "x173          -0.0187      0.013     -1.474      0.141      -0.044       0.006\n",
      "x174           0.0014      0.013      0.112      0.911      -0.023       0.026\n",
      "x175          -0.0167      0.013     -1.316      0.188      -0.042       0.008\n",
      "x176           0.0036      0.013      0.277      0.782      -0.022       0.029\n",
      "x177           0.0200      0.013      1.540      0.124      -0.005       0.045\n",
      "x178           0.0050      0.013      0.387      0.699      -0.020       0.030\n",
      "x179          -0.0228      0.013     -1.802      0.072      -0.048       0.002\n",
      "x180           0.0056      0.013      0.447      0.655      -0.019       0.030\n",
      "x181           0.0124      0.013      0.962      0.336      -0.013       0.038\n",
      "x182           0.0187      0.013      1.469      0.142      -0.006       0.044\n",
      "x183           0.0052      0.013      0.402      0.688      -0.020       0.030\n",
      "x184           0.0198      0.013      1.546      0.122      -0.005       0.045\n",
      "x185           0.0024      0.013      0.189      0.850      -0.023       0.027\n",
      "x186           0.0247      0.013      1.928      0.054      -0.000       0.050\n",
      "x187           0.0090      0.013      0.697      0.486      -0.016       0.034\n",
      "x188           0.0068      0.013      0.534      0.593      -0.018       0.032\n",
      "x189           0.0250      0.013      1.948      0.051      -0.000       0.050\n",
      "x190           0.0100      0.013      0.775      0.438      -0.015       0.035\n",
      "x191          -0.0056      0.013     -0.448      0.654      -0.030       0.019\n",
      "x192           0.0020      0.013      0.159      0.874      -0.023       0.027\n",
      "x193          -0.0181      0.013     -1.423      0.155      -0.043       0.007\n",
      "x194          -0.0051      0.013     -0.396      0.692      -0.030       0.020\n",
      "x195           0.0079      0.013      0.626      0.532      -0.017       0.033\n",
      "x196          -0.0085      0.013     -0.656      0.512      -0.034       0.017\n",
      "x197          -0.0110      0.013     -0.852      0.394      -0.036       0.014\n",
      "x198          -0.0080      0.013     -0.621      0.535      -0.033       0.017\n",
      "x199           0.0062      0.013      0.489      0.625      -0.019       0.031\n",
      "x200          -0.0301      0.013     -2.376      0.018      -0.055      -0.005\n",
      "x201          -0.0007      0.013     -0.053      0.958      -0.026       0.025\n",
      "x202           0.0170      0.013      1.324      0.186      -0.008       0.042\n",
      "x203           0.0021      0.013      0.164      0.870      -0.023       0.027\n",
      "x204           0.0179      0.013      1.398      0.162      -0.007       0.043\n",
      "x205           0.0104      0.013      0.822      0.411      -0.014       0.035\n",
      "x206          -0.0051      0.013     -0.405      0.686      -0.030       0.020\n",
      "x207          -0.0051      0.013     -0.404      0.686      -0.030       0.020\n",
      "x208          -0.0066      0.013     -0.525      0.600      -0.031       0.018\n",
      "x209          -0.0005      0.013     -0.041      0.967      -0.026       0.025\n",
      "x210           0.0187      0.013      1.476      0.140      -0.006       0.044\n",
      "x211          -0.0018      0.013     -0.143      0.886      -0.027       0.023\n",
      "x212          -0.0307      0.013     -2.410      0.016      -0.056      -0.006\n",
      "x213           0.0094      0.013      0.736      0.462      -0.016       0.034\n",
      "x214           0.0032      0.013      0.250      0.802      -0.022       0.028\n",
      "x215           0.0173      0.013      1.348      0.178      -0.008       0.042\n",
      "x216           0.0200      0.013      1.571      0.116      -0.005       0.045\n",
      "x217          -0.0026      0.013     -0.202      0.840      -0.028       0.023\n",
      "x218           0.0029      0.013      0.224      0.823      -0.022       0.028\n",
      "x219          -0.0154      0.013     -1.211      0.226      -0.040       0.010\n",
      "x220           0.0141      0.013      1.109      0.267      -0.011       0.039\n",
      "x221           0.0272      0.013      2.104      0.035       0.002       0.053\n",
      "x222          -0.0006      0.013     -0.048      0.961      -0.026       0.024\n",
      "x223           0.0258      0.013      2.017      0.044       0.001       0.051\n",
      "x224          -0.0017      0.013     -0.132      0.895      -0.027       0.023\n",
      "x225          -0.0106      0.013     -0.839      0.401      -0.035       0.014\n",
      "x226          -0.0117      0.013     -0.908      0.364      -0.037       0.014\n",
      "x227          -0.0081      0.013     -0.640      0.522      -0.033       0.017\n",
      "x228          -0.0038      0.013     -0.303      0.762      -0.029       0.021\n",
      "x229          -0.0040      0.013     -0.316      0.752      -0.029       0.021\n",
      "x230          -0.0131      0.013     -1.022      0.307      -0.038       0.012\n",
      "x231          -0.0123      0.013     -0.954      0.340      -0.037       0.013\n",
      "x232           0.0117      0.013      0.920      0.358      -0.013       0.037\n",
      "x233           0.0066      0.013      0.515      0.607      -0.019       0.032\n",
      "x234          -0.0207      0.013     -1.625      0.104      -0.046       0.004\n",
      "x235           0.0063      0.013      0.494      0.621      -0.019       0.031\n",
      "x236           0.0145      0.013      1.135      0.256      -0.011       0.040\n",
      "x237          -0.0037      0.013     -0.289      0.773      -0.029       0.021\n",
      "x238           0.0121      0.013      0.945      0.345      -0.013       0.037\n",
      "x239          -0.0121      0.013     -0.939      0.348      -0.037       0.013\n",
      "x240           0.0129      0.013      1.000      0.317      -0.012       0.038\n",
      "x241           0.0176      0.013      1.375      0.169      -0.007       0.043\n",
      "x242           0.0046      0.013      0.360      0.719      -0.020       0.029\n",
      "x243           0.0275      0.013      2.157      0.031       0.003       0.053\n",
      "x244           0.0144      0.013      1.138      0.255      -0.010       0.039\n",
      "x245           0.0047      0.013      0.370      0.711      -0.020       0.030\n",
      "x246           0.0033      0.013      0.255      0.799      -0.022       0.029\n",
      "x247           0.0147      0.013      1.156      0.248      -0.010       0.040\n",
      "x248           0.0075      0.013      0.594      0.553      -0.017       0.032\n",
      "x249          -0.0009      0.013     -0.068      0.946      -0.026       0.024\n",
      "x250          -0.0051      0.013     -0.400      0.689      -0.030       0.020\n",
      "x251           0.0069      0.013      0.541      0.588      -0.018       0.032\n",
      "x252          -0.0121      0.013     -0.938      0.348      -0.037       0.013\n",
      "x253           0.0267      0.013      2.105      0.035       0.002       0.052\n",
      "x254           0.0150      0.013      1.190      0.234      -0.010       0.040\n",
      "x255           0.0146      0.013      1.143      0.253      -0.010       0.040\n",
      "x256           0.0087      0.013      0.683      0.495      -0.016       0.034\n",
      "x257           0.0146      0.013      1.137      0.256      -0.011       0.040\n",
      "x258           0.0149      0.013      1.171      0.241      -0.010       0.040\n",
      "x259           0.0038      0.013      0.301      0.763      -0.021       0.029\n",
      "x260           0.0029      0.013      0.230      0.818      -0.022       0.028\n",
      "x261           0.0122      0.013      0.963      0.336      -0.013       0.037\n",
      "x262           0.0072      0.013      0.558      0.577      -0.018       0.032\n",
      "x263           0.0266      0.013      2.082      0.037       0.002       0.052\n",
      "x264           0.0047      0.013      0.366      0.714      -0.020       0.030\n",
      "x265           0.0284      0.013      2.241      0.025       0.004       0.053\n",
      "x266           0.0113      0.013      0.881      0.378      -0.014       0.037\n",
      "x267           0.0165      0.013      1.301      0.193      -0.008       0.041\n",
      "x268           0.0070      0.013      0.545      0.586      -0.018       0.032\n",
      "x269           0.0282      0.013      2.243      0.025       0.004       0.053\n",
      "x270           0.0185      0.013      1.447      0.148      -0.007       0.043\n",
      "x271           0.0103      0.013      0.815      0.415      -0.014       0.035\n",
      "x272           0.0132      0.013      1.045      0.296      -0.012       0.038\n",
      "x273          -0.0095      0.013     -0.746      0.455      -0.034       0.015\n",
      "x274           0.0159      0.013      1.253      0.210      -0.009       0.041\n",
      "x275           0.0208      0.013      1.602      0.109      -0.005       0.046\n",
      "x276           0.0108      0.013      0.841      0.401      -0.014       0.036\n",
      "x277           0.0308      0.013      2.428      0.015       0.006       0.056\n",
      "x278           0.0095      0.013      0.745      0.456      -0.015       0.034\n",
      "x279           0.0121      0.013      0.949      0.343      -0.013       0.037\n",
      "x280           0.0010      0.013      0.076      0.939      -0.024       0.026\n",
      "x281          -0.0184      0.013     -1.441      0.150      -0.043       0.007\n",
      "x282           0.0018      0.013      0.143      0.887      -0.023       0.027\n",
      "x283           0.0139      0.013      1.107      0.268      -0.011       0.039\n",
      "x284           0.0108      0.013      0.836      0.403      -0.015       0.036\n",
      "x285          -0.0042      0.013     -0.327      0.744      -0.029       0.021\n",
      "x286           0.0075      0.013      0.592      0.554      -0.017       0.032\n",
      "x287           0.0170      0.013      1.333      0.183      -0.008       0.042\n",
      "x288           0.0102      0.013      0.800      0.424      -0.015       0.035\n",
      "x289          -0.0142      0.013     -1.115      0.265      -0.039       0.011\n",
      "x290           0.0189      0.013      1.478      0.140      -0.006       0.044\n",
      "x291           0.0064      0.013      0.503      0.615      -0.019       0.032\n",
      "x292          -0.0224      0.013     -1.787      0.074      -0.047       0.002\n",
      "x293           0.0082      0.013      0.648      0.517      -0.017       0.033\n",
      "x294          -0.0098      0.013     -0.770      0.441      -0.035       0.015\n",
      "x295           0.0070      0.013      0.554      0.579      -0.018       0.032\n",
      "x296          -0.0004      0.013     -0.031      0.976      -0.026       0.025\n",
      "x297           0.0161      0.013      1.260      0.208      -0.009       0.041\n",
      "x298           0.0076      0.013      0.592      0.554      -0.017       0.033\n",
      "x299       -8.874e-05      0.013     -0.007      0.994      -0.025       0.025\n",
      "x300           0.0061      0.013      0.480      0.631      -0.019       0.031\n",
      "x301           0.0277      0.013      2.157      0.031       0.003       0.053\n",
      "x302           0.0249      0.013      1.968      0.049    9.37e-05       0.050\n",
      "x303           0.0066      0.013      0.517      0.605      -0.018       0.032\n",
      "x304          -0.0108      0.013     -0.843      0.399      -0.036       0.014\n",
      "x305           0.0137      0.013      1.085      0.278      -0.011       0.038\n",
      "x306           0.0100      0.013      0.777      0.437      -0.015       0.035\n",
      "x307          -0.0059      0.013     -0.468      0.640      -0.031       0.019\n",
      "x308           0.0093      0.013      0.730      0.466      -0.016       0.034\n",
      "x309          -0.0026      0.013     -0.209      0.834      -0.027       0.022\n",
      "x310          -0.0016      0.013     -0.125      0.901      -0.027       0.024\n",
      "x311          -0.0052      0.013     -0.403      0.687      -0.030       0.020\n",
      "x312          -0.0018      0.013     -0.143      0.886      -0.027       0.023\n",
      "x313          -0.0048      0.013     -0.373      0.709      -0.030       0.020\n",
      "x314           0.0105      0.013      0.816      0.414      -0.015       0.036\n",
      "x315           0.0116      0.013      0.906      0.365      -0.014       0.037\n",
      "x316           0.0105      0.013      0.818      0.413      -0.015       0.036\n",
      "x317          -0.0104      0.013     -0.821      0.412      -0.035       0.014\n",
      "x318          -0.0053      0.013     -0.409      0.683      -0.030       0.020\n",
      "x319           0.0146      0.013      1.142      0.253      -0.010       0.040\n",
      "x320           0.0028      0.013      0.221      0.825      -0.022       0.028\n",
      "x321           0.0065      0.013      0.514      0.607      -0.018       0.032\n",
      "x322           0.0032      0.013      0.252      0.801      -0.022       0.028\n",
      "x323           0.0270      0.013      2.120      0.034       0.002       0.052\n",
      "x324           0.0098      0.013      0.760      0.447      -0.015       0.035\n",
      "x325           0.0098      0.013      0.759      0.448      -0.015       0.035\n",
      "x326           0.0036      0.013      0.285      0.775      -0.021       0.028\n",
      "x327           0.0138      0.012      1.103      0.270      -0.011       0.038\n",
      "x328           0.0201      0.013      1.587      0.113      -0.005       0.045\n",
      "x329           0.0119      0.013      0.945      0.345      -0.013       0.037\n",
      "x330          -0.0046      0.013     -0.358      0.721      -0.030       0.021\n",
      "x331           0.0207      0.013      1.625      0.104      -0.004       0.046\n",
      "x332           0.0197      0.013      1.547      0.122      -0.005       0.045\n",
      "x333           0.0111      0.013      0.862      0.389      -0.014       0.036\n",
      "x334          -0.0004      0.013     -0.033      0.974      -0.026       0.025\n",
      "x335           0.0093      0.013      0.729      0.466      -0.016       0.034\n",
      "x336           0.0117      0.013      0.922      0.356      -0.013       0.037\n",
      "x337          -0.0056      0.013     -0.436      0.663      -0.031       0.019\n",
      "x338          -0.0209      0.013     -1.609      0.108      -0.046       0.005\n",
      "x339           0.0159      0.013      1.249      0.212      -0.009       0.041\n",
      "x340           0.0215      0.013      1.677      0.094      -0.004       0.047\n",
      "x341           0.0111      0.013      0.867      0.386      -0.014       0.036\n",
      "x342           0.0096      0.013      0.751      0.452      -0.015       0.035\n",
      "x343           0.0155      0.013      1.226      0.220      -0.009       0.040\n",
      "x344          -0.0003      0.013     -0.024      0.981      -0.025       0.025\n",
      "x345           0.0023      0.013      0.178      0.859      -0.023       0.027\n",
      "x346           0.0077      0.013      0.601      0.548      -0.017       0.033\n",
      "x347           0.0277      0.013      2.174      0.030       0.003       0.053\n",
      "x348           0.0024      0.013      0.189      0.850      -0.023       0.028\n",
      "x349           0.0089      0.013      0.704      0.482      -0.016       0.034\n",
      "x350          -0.0001      0.013     -0.010      0.992      -0.025       0.025\n",
      "x351          -0.0087      0.013     -0.686      0.493      -0.034       0.016\n",
      "x352           0.0132      0.013      1.035      0.301      -0.012       0.038\n",
      "x353           0.0213      0.013      1.667      0.096      -0.004       0.046\n",
      "x354          -0.0040      0.013     -0.312      0.755      -0.029       0.021\n",
      "x355           0.0071      0.013      0.555      0.579      -0.018       0.032\n",
      "x356           0.0025      0.013      0.195      0.845      -0.023       0.027\n",
      "x357           0.0106      0.013      0.842      0.400      -0.014       0.035\n",
      "x358          -0.0016      0.013     -0.130      0.897      -0.027       0.023\n",
      "x359           0.0013      0.013      0.100      0.920      -0.024       0.026\n",
      "x360           0.0022      0.013      0.167      0.867      -0.023       0.027\n",
      "x361          -0.0086      0.013     -0.673      0.501      -0.034       0.017\n",
      "x362           0.0030      0.013      0.235      0.814      -0.022       0.028\n",
      "x363           0.0017      0.013      0.135      0.892      -0.023       0.027\n",
      "x364           0.0011      0.013      0.087      0.931      -0.024       0.027\n",
      "x365           0.0068      0.013      0.533      0.594      -0.018       0.032\n",
      "x366           0.0231      0.013      1.804      0.071      -0.002       0.048\n",
      "x367           0.0030      0.013      0.236      0.814      -0.022       0.028\n",
      "x368           0.0216      0.013      1.689      0.091      -0.003       0.047\n",
      "x369           0.0069      0.013      0.540      0.589      -0.018       0.032\n",
      "x370           0.0081      0.013      0.635      0.526      -0.017       0.033\n",
      "x371          -0.0007      0.013     -0.054      0.957      -0.026       0.024\n",
      "x372          -0.0108      0.013     -0.843      0.399      -0.036       0.014\n",
      "x373           0.0076      0.013      0.599      0.549      -0.017       0.032\n",
      "x374           0.0339      0.013      2.647      0.008       0.009       0.059\n",
      "x375          -0.0131      0.013     -1.009      0.313      -0.038       0.012\n",
      "x376           0.0144      0.013      1.129      0.259      -0.011       0.039\n",
      "x377          -0.0075      0.013     -0.591      0.555      -0.033       0.017\n",
      "x378           0.0401      0.013      3.150      0.002       0.015       0.065\n",
      "x379           0.0213      0.013      1.668      0.095      -0.004       0.046\n",
      "x380           0.0025      0.013      0.198      0.843      -0.023       0.028\n",
      "x381           0.0066      0.013      0.517      0.605      -0.018       0.032\n",
      "x382           0.0111      0.013      0.876      0.381      -0.014       0.036\n",
      "x383          -0.0051      0.013     -0.399      0.690      -0.030       0.020\n",
      "x384           0.0066      0.013      0.518      0.605      -0.018       0.032\n",
      "x385          -0.0022      0.013     -0.174      0.862      -0.027       0.023\n",
      "x386           0.0036      0.013      0.284      0.776      -0.021       0.028\n",
      "x387           0.0169      0.013      1.323      0.186      -0.008       0.042\n",
      "x388           0.0221      0.013      1.731      0.083      -0.003       0.047\n",
      "x389          -0.0204      0.013     -1.600      0.110      -0.045       0.005\n",
      "x390           0.0103      0.013      0.801      0.423      -0.015       0.035\n",
      "x391          -0.0030      0.013     -0.232      0.816      -0.028       0.022\n",
      "x392          -0.0110      0.013     -0.869      0.385      -0.036       0.014\n",
      "x393           0.0331      0.013      2.630      0.009       0.008       0.058\n",
      "x394           0.0133      0.013      1.042      0.297      -0.012       0.038\n",
      "x395           0.0274      0.013      2.146      0.032       0.002       0.052\n",
      "x396           0.0146      0.013      1.149      0.251      -0.010       0.040\n",
      "x397           0.0007      0.013      0.055      0.956      -0.024       0.026\n",
      "x398           0.0024      0.013      0.186      0.853      -0.022       0.027\n",
      "x399           0.0242      0.013      1.906      0.057      -0.001       0.049\n",
      "x400          -0.0142      0.013     -1.095      0.274      -0.040       0.011\n",
      "x401          -0.0021      0.013     -0.162      0.871      -0.027       0.023\n",
      "x402          -0.0005      0.013     -0.037      0.971      -0.026       0.025\n",
      "x403           0.0022      0.013      0.170      0.865      -0.023       0.027\n",
      "x404          -0.0078      0.013     -0.611      0.541      -0.033       0.017\n",
      "x405           0.0156      0.013      1.214      0.225      -0.010       0.041\n",
      "x406          -0.0061      0.013     -0.475      0.635      -0.031       0.019\n",
      "x407           0.0110      0.013      0.854      0.393      -0.014       0.036\n",
      "x408           0.0086      0.013      0.676      0.499      -0.016       0.033\n",
      "x409          -0.0026      0.013     -0.205      0.837      -0.027       0.022\n",
      "x410           0.0007      0.013      0.054      0.957      -0.024       0.026\n",
      "x411           0.0015      0.013      0.119      0.905      -0.023       0.026\n",
      "x412           0.0249      0.013      1.959      0.050   -1.04e-05       0.050\n",
      "x413           0.0197      0.013      1.548      0.122      -0.005       0.045\n",
      "x414           0.0106      0.013      0.821      0.412      -0.015       0.036\n",
      "x415           0.0164      0.013      1.276      0.202      -0.009       0.041\n",
      "x416          -0.0158      0.013     -1.229      0.219      -0.041       0.009\n",
      "x417           0.0041      0.013      0.327      0.743      -0.021       0.029\n",
      "x418           0.0030      0.013      0.234      0.815      -0.022       0.028\n",
      "x419          -0.0081      0.013     -0.639      0.523      -0.033       0.017\n",
      "x420          -0.0169      0.013     -1.312      0.190      -0.042       0.008\n",
      "x421           0.0262      0.013      2.033      0.042       0.001       0.051\n",
      "x422           0.0119      0.013      0.915      0.360      -0.014       0.037\n",
      "x423           0.0128      0.013      0.983      0.326      -0.013       0.038\n",
      "x424           0.0135      0.013      1.059      0.290      -0.012       0.039\n",
      "x425           0.0058      0.013      0.452      0.652      -0.019       0.031\n",
      "x426           0.0049      0.013      0.390      0.697      -0.020       0.030\n",
      "x427          -0.0230      0.013     -1.777      0.076      -0.048       0.002\n",
      "x428          -0.0133      0.013     -1.041      0.298      -0.038       0.012\n",
      "x429           0.0251      0.013      1.972      0.049       0.000       0.050\n",
      "x430           0.0069      0.013      0.544      0.586      -0.018       0.032\n",
      "x431           0.0239      0.013      1.863      0.063      -0.001       0.049\n",
      "x432           0.0011      0.013      0.083      0.934      -0.024       0.026\n",
      "x433           0.0116      0.013      0.917      0.359      -0.013       0.036\n",
      "x434          -0.0205      0.013     -1.605      0.108      -0.045       0.005\n",
      "x435          -0.0005      0.013     -0.039      0.969      -0.026       0.025\n",
      "x436           0.0120      0.013      0.937      0.349      -0.013       0.037\n",
      "x437          -0.0009      0.013     -0.070      0.944      -0.026       0.024\n",
      "x438          -0.0048      0.013     -0.380      0.704      -0.030       0.020\n",
      "x439           0.0008      0.013      0.060      0.952      -0.024       0.026\n",
      "x440          -0.0074      0.013     -0.575      0.565      -0.033       0.018\n",
      "x441           0.0071      0.013      0.560      0.576      -0.018       0.032\n",
      "x442          -0.0262      0.013     -2.032      0.042      -0.051      -0.001\n",
      "x443           0.0285      0.013      2.241      0.025       0.004       0.053\n",
      "x444           0.0134      0.013      1.051      0.293      -0.012       0.038\n",
      "x445           0.0071      0.013      0.553      0.580      -0.018       0.032\n",
      "x446          -0.0239      0.013     -1.888      0.059      -0.049       0.001\n",
      "x447           0.0020      0.013      0.160      0.873      -0.023       0.027\n",
      "x448           0.0103      0.013      0.799      0.424      -0.015       0.035\n",
      "x449          -0.0118      0.013     -0.917      0.359      -0.037       0.013\n",
      "x450           0.0085      0.013      0.672      0.502      -0.016       0.033\n",
      "x451           0.0071      0.013      0.554      0.580      -0.018       0.032\n",
      "x452          -0.0145      0.013     -1.136      0.256      -0.040       0.011\n",
      "x453           0.0289      0.013      2.235      0.025       0.004       0.054\n",
      "x454          -0.0195      0.013     -1.538      0.124      -0.044       0.005\n",
      "x455           0.0223      0.013      1.749      0.080      -0.003       0.047\n",
      "x456           0.0047      0.013      0.364      0.716      -0.021       0.030\n",
      "x457          -0.0060      0.013     -0.478      0.633      -0.031       0.019\n",
      "x458           0.0008      0.013      0.065      0.948      -0.024       0.026\n",
      "x459           0.0069      0.013      0.548      0.584      -0.018       0.032\n",
      "x460           0.0075      0.013      0.582      0.561      -0.018       0.033\n",
      "x461           0.0060      0.013      0.473      0.637      -0.019       0.031\n",
      "x462           0.0124      0.013      0.976      0.329      -0.012       0.037\n",
      "x463           0.0138      0.013      1.090      0.276      -0.011       0.039\n",
      "x464           0.0035      0.013      0.276      0.782      -0.021       0.029\n",
      "x465          -0.0051      0.013     -0.402      0.688      -0.030       0.020\n",
      "x466          -0.0155      0.013     -1.219      0.223      -0.040       0.009\n",
      "x467          -0.0056      0.013     -0.436      0.663      -0.031       0.020\n",
      "x468           0.0128      0.013      1.006      0.314      -0.012       0.038\n",
      "x469          -0.0062      0.013     -0.483      0.629      -0.031       0.019\n",
      "x470           0.0154      0.013      1.226      0.220      -0.009       0.040\n",
      "x471           0.0069      0.013      0.547      0.584      -0.018       0.032\n",
      "x472          -0.0102      0.013     -0.795      0.426      -0.035       0.015\n",
      "x473           0.0132      0.013      1.033      0.302      -0.012       0.038\n",
      "x474           0.0199      0.013      1.556      0.120      -0.005       0.045\n",
      "x475           0.0095      0.013      0.742      0.458      -0.016       0.035\n",
      "x476           0.0100      0.013      0.793      0.428      -0.015       0.035\n",
      "x477           0.0342      0.013      2.686      0.007       0.009       0.059\n",
      "x478          -0.0046      0.013     -0.368      0.713      -0.029       0.020\n",
      "x479          -0.0160      0.013     -1.267      0.205      -0.041       0.009\n",
      "x480          -0.0126      0.013     -0.991      0.321      -0.037       0.012\n",
      "x481           0.0049      0.013      0.391      0.696      -0.020       0.030\n",
      "x482           0.0147      0.013      1.147      0.251      -0.010       0.040\n",
      "x483           0.0301      0.013      2.345      0.019       0.005       0.055\n",
      "x484           0.0320      0.013      2.511      0.012       0.007       0.057\n",
      "x485          -0.0102      0.013     -0.794      0.427      -0.035       0.015\n",
      "x486           0.0061      0.013      0.480      0.632      -0.019       0.031\n",
      "x487          -0.0043      0.013     -0.335      0.737      -0.029       0.021\n",
      "x488           0.0054      0.013      0.416      0.678      -0.020       0.031\n",
      "x489          -0.0095      0.013     -0.741      0.459      -0.035       0.016\n",
      "x490          -0.0134      0.013     -1.039      0.299      -0.039       0.012\n",
      "x491           0.0097      0.013      0.766      0.444      -0.015       0.035\n",
      "x492           0.0090      0.013      0.699      0.484      -0.016       0.034\n",
      "x493           0.0023      0.013      0.182      0.856      -0.023       0.028\n",
      "x494           0.0329      0.013      2.568      0.010       0.008       0.058\n",
      "x495           0.0181      0.013      1.400      0.162      -0.007       0.043\n",
      "x496           0.0202      0.013      1.601      0.109      -0.005       0.045\n",
      "x497          -0.0041      0.013     -0.324      0.746      -0.029       0.021\n",
      "x498          -0.0031      0.013     -0.239      0.811      -0.028       0.022\n",
      "x499           0.0156      0.013      1.230      0.219      -0.009       0.041\n",
      "x500          -0.0037      0.013     -0.290      0.772      -0.029       0.021\n",
      "x501           0.0207      0.013      1.620      0.105      -0.004       0.046\n",
      "==============================================================================\n",
      "Omnibus:                        0.469   Durbin-Watson:                   1.667\n",
      "Prob(Omnibus):                  0.791   Jarque-Bera (JB):                0.502\n",
      "Skew:                           0.003   Prob(JB):                        0.778\n",
      "Kurtosis:                       2.966   Cond. No.                         1.92\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Multivariate regression\n",
    "import statsmodels.api as sm\n",
    "mod = sm.OLS(y, np.c_[t,x])\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7b35f394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient Results:  X is None, please call intercept_inference to learn the constant!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>CATE Intercept Results</caption>\n",
       "<tr>\n",
       "         <td></td>        <th>point_estimate</th> <th>stderr</th>  <th>zstat</th> <th>pvalue</th> <th>ci_lower</th> <th>ci_upper</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cate_intercept</th>      <td>0.511</td>      <td>0.01</td>  <td>50.476</td>   <td>0.0</td>    <td>0.491</td>    <td>0.531</td> \n",
       "</tr>\n",
       "</table><br/><br/><sub>A linear parametric conditional average treatment effect (CATE) model was fitted:<br/>$Y = \\Theta(X)\\cdot T + g(X, W) + \\epsilon$<br/>where for every outcome $i$ and treatment $j$ the CATE $\\Theta_{ij}(X)$ has the form:<br/>$\\Theta_{ij}(X) = X' coef_{ij} + cate\\_intercept_{ij}$<br/>Coefficient Results table portrays the $coef_{ij}$ parameter vector for each outcome $i$ and treatment $j$. Intercept Results table portrays the $cate\\_intercept_{ij}$ parameter.</sub>"
      ],
      "text/plain": [
       "<class 'econml.utilities.Summary'>\n",
       "\"\"\"\n",
       "                       CATE Intercept Results                       \n",
       "====================================================================\n",
       "               point_estimate stderr zstat  pvalue ci_lower ci_upper\n",
       "--------------------------------------------------------------------\n",
       "cate_intercept          0.511   0.01 50.476    0.0    0.491    0.531\n",
       "--------------------------------------------------------------------\n",
       "\n",
       "<sub>A linear parametric conditional average treatment effect (CATE) model was fitted:\n",
       "$Y = \\Theta(X)\\cdot T + g(X, W) + \\epsilon$\n",
       "where for every outcome $i$ and treatment $j$ the CATE $\\Theta_{ij}(X)$ has the form:\n",
       "$\\Theta_{ij}(X) = X' coef_{ij} + cate\\_intercept_{ij}$\n",
       "Coefficient Results table portrays the $coef_{ij}$ parameter vector for each outcome $i$ and treatment $j$. Intercept Results table portrays the $cate\\_intercept_{ij}$ parameter.</sub>\n",
       "\"\"\""
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DML regression - still yeilds unbiased estimate of ATE \n",
    "from econml.dml import LinearDML\n",
    "est = LinearDML(random_state=1)\n",
    "est.fit(y, t, X=None,W=x)\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de52128",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
