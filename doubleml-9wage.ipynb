{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cd77248",
   "metadata": {},
   "source": [
    "# Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b68db5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from doubleml.datasets import make_plr_CCDDHNR2018, make_plr_turrell2018\n",
    "np.random.seed(1234)\n",
    "n_rep = 1\n",
    "n_obs = 10000\n",
    "n_vars = 10\n",
    "alpha = 0.5\n",
    "data = list()\n",
    "from sklearn.datasets import make_spd_matrix\n",
    "\n",
    "def g(x):\n",
    "    return np.exp(x)\n",
    "\n",
    "def m(x):\n",
    "    return np.sin(x)\n",
    "\n",
    "theta = alpha = 0.5 \n",
    "b = [1/k for k in range(1,n_vars+1)] # x weights \n",
    "sigma = make_spd_matrix(n_vars, random_state=42)\n",
    "\n",
    "for i_rep in range(n_rep):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    df = pd.read_csv('/Users/pranjal/Desktop/Causal-Inference/data/wage.csv')\n",
    "    cat = df.select_dtypes('object').columns\n",
    "    df = pd.get_dummies(df, columns = cat, drop_first = True)\n",
    "    outcome = 'lwage'\n",
    "    treatment = 'educ'\n",
    "    #rest = list(df.drop([outcome, treatment], axis = 1).columns)\n",
    "    rest = ['exper','age', 'kidslt6', 'kidsge6']\n",
    "    df = df[[outcome] + [treatment] + rest]\n",
    "    df = df.dropna()\n",
    "    y = df[outcome]\n",
    "    d = df[treatment]\n",
    "    x = df[rest].astype('float')\n",
    "    data.append((x, y, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8d7dc026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inlf</th>\n",
       "      <th>hours</th>\n",
       "      <th>kidslt6</th>\n",
       "      <th>kidsge6</th>\n",
       "      <th>age</th>\n",
       "      <th>educ</th>\n",
       "      <th>wage</th>\n",
       "      <th>repwage</th>\n",
       "      <th>hushrs</th>\n",
       "      <th>husage</th>\n",
       "      <th>...</th>\n",
       "      <th>faminc</th>\n",
       "      <th>mtr</th>\n",
       "      <th>motheduc</th>\n",
       "      <th>fatheduc</th>\n",
       "      <th>unem</th>\n",
       "      <th>city</th>\n",
       "      <th>exper</th>\n",
       "      <th>nwifeinc</th>\n",
       "      <th>lwage</th>\n",
       "      <th>expersq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1610</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>12</td>\n",
       "      <td>3.3540</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2708</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>16310</td>\n",
       "      <td>0.7215</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>10.910060</td>\n",
       "      <td>1.210154</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1656</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>1.3889</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2310</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>21800</td>\n",
       "      <td>0.6615</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>19.499981</td>\n",
       "      <td>0.328512</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1980</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>12</td>\n",
       "      <td>4.5455</td>\n",
       "      <td>4.04</td>\n",
       "      <td>3072</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>21040</td>\n",
       "      <td>0.6915</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>12.039910</td>\n",
       "      <td>1.514138</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>456</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0965</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1920</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>7300</td>\n",
       "      <td>0.7815</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6.799996</td>\n",
       "      <td>0.092123</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1568</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>14</td>\n",
       "      <td>4.5918</td>\n",
       "      <td>3.60</td>\n",
       "      <td>2000</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>27300</td>\n",
       "      <td>0.6215</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>9.5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>20.100058</td>\n",
       "      <td>1.524272</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   inlf  hours  kidslt6  kidsge6  age  educ    wage  repwage  hushrs  husage  \\\n",
       "0     1   1610        1        0   32    12  3.3540     2.65    2708      34   \n",
       "1     1   1656        0        2   30    12  1.3889     2.65    2310      30   \n",
       "2     1   1980        1        3   35    12  4.5455     4.04    3072      40   \n",
       "3     1    456        0        3   34    12  1.0965     3.25    1920      53   \n",
       "4     1   1568        1        2   31    14  4.5918     3.60    2000      32   \n",
       "\n",
       "   ...  faminc     mtr  motheduc  fatheduc  unem  city  exper   nwifeinc  \\\n",
       "0  ...   16310  0.7215        12         7   5.0     0     14  10.910060   \n",
       "1  ...   21800  0.6615         7         7  11.0     1      5  19.499981   \n",
       "2  ...   21040  0.6915        12         7   5.0     0     15  12.039910   \n",
       "3  ...    7300  0.7815         7         7   5.0     0      6   6.799996   \n",
       "4  ...   27300  0.6215        12        14   9.5     1      7  20.100058   \n",
       "\n",
       "      lwage  expersq  \n",
       "0  1.210154      196  \n",
       "1  0.328512       25  \n",
       "2  1.514138      225  \n",
       "3  0.092123       36  \n",
       "4  1.524272       49  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/pranjal/Desktop/Causal-Inference/data/wage.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27aa0664",
   "metadata": {},
   "source": [
    "# Naive ML\n",
    "- no orthogonalisation, no crossfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "58f81856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_orth_score(y, d, l_hat, m_hat, g_hat, smpls):\n",
    "    psi_a = -np.multiply(d, d)\n",
    "    psi_b = np.multiply(d, y - g_hat)\n",
    "    return psi_a, psi_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "226e7de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "================== DoubleMLData Object ==================\n",
      "\n",
      "------------------ Data summary      ------------------\n",
      "Outcome variable: y\n",
      "Treatment variable(s): ['d']\n",
      "Covariates: ['X1', 'X2', 'X3', 'X4']\n",
      "Instrument variable(s): None\n",
      "No. Observations: 428\n",
      "\n",
      "------------------ DataFrame info    ------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 428 entries, 0 to 427\n",
      "Columns: 6 entries, X1 to d\n",
      "dtypes: float64(6)\n",
      "memory usage: 20.2 KB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from doubleml import DoubleMLData\n",
    "from doubleml import DoubleMLPLR\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.base import clone\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "face_colors = sns.color_palette('pastel')\n",
    "edge_colors = sns.color_palette('dark')\n",
    "np.random.seed(1111)\n",
    "ml_l = RandomForestRegressor()\n",
    "ml_m = RandomForestRegressor()\n",
    "#ml_m = LogisticRegression()\n",
    "ml_g = clone(ml_l)\n",
    "\n",
    "# to speed up the illustration we hard-code the simulation results\n",
    "theta_nonorth = np.empty(n_rep)\n",
    "se_nonorth = np.empty(n_rep)\n",
    "t_nonorth = np.empty(n_rep)\n",
    "p_nonorth = np.empty(n_rep)\n",
    "# to run the full simulation uncomment the following line to fit the model for every dataset and not just for the first dataset\n",
    "for i_rep in range(n_rep):\n",
    "    print(i_rep)\n",
    "#for i_rep in range(1):\n",
    "    (x, y, d) = data[i_rep]\n",
    "    obj_dml_data = DoubleMLData.from_arrays(x, y.ravel(), d.ravel())\n",
    "    print(obj_dml_data)\n",
    "    obj_dml_plr_nonorth = DoubleMLPLR(obj_dml_data,\n",
    "                                      ml_l, ml_m, ml_g,\n",
    "                                      n_folds=1,\n",
    "                                      apply_cross_fitting=False,\n",
    "                                      score=non_orth_score)\n",
    "    obj_dml_plr_nonorth.fit()\n",
    "    theta_nonorth[i_rep] = obj_dml_plr_nonorth.coef[0]\n",
    "    se_nonorth[i_rep] = obj_dml_plr_nonorth.se[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c563855",
   "metadata": {},
   "source": [
    "# Orthogonal Machine Learning\n",
    "- resolves regularization bias, but not overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f2682d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2222)\n",
    "# to speed up the illustration we hard-code the simulation results\n",
    "theta_orth_nosplit = np.empty(n_rep)\n",
    "se_orth_nosplit = np.empty(n_rep)\n",
    "# to run the full simulation uncomment the following line to fit the model for every dataset and not just for the first dataset\n",
    "for i_rep in range(n_rep):\n",
    "    print(i_rep)\n",
    "#for i_rep in range(1):\n",
    "    (x, y, d) = data[i_rep]\n",
    "    obj_dml_data = DoubleMLData.from_arrays(x, y, d)\n",
    "    obj_dml_plr_orth_nosplit = DoubleMLPLR(obj_dml_data,\n",
    "                                           ml_l, ml_m, ml_g,\n",
    "                                           n_folds=1,\n",
    "                                           score='IV-type',\n",
    "                                           apply_cross_fitting=False)\n",
    "    obj_dml_plr_orth_nosplit.fit()\n",
    "    theta_orth_nosplit[i_rep] = obj_dml_plr_orth_nosplit.coef[0]\n",
    "    se_orth_nosplit[i_rep] = obj_dml_plr_orth_nosplit.se[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa0e04f",
   "metadata": {},
   "source": [
    "# Orthogonal ML + Cross fitting (DML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1da32ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "# to speed up the illustration we hard-code the simulation results\n",
    "theta_dml = np.empty(n_rep)\n",
    "se_dml = np.empty(n_rep)\n",
    "\n",
    "# to run the full simulation uncomment the following line to fit the model for every dataset and not just for the first dataset\n",
    "for i_rep in range(n_rep):\n",
    "    print(i_rep)\n",
    "    (x, y, d) = data[i_rep]\n",
    "    obj_dml_data = DoubleMLData.from_arrays(x, y, d)\n",
    "    obj_dml_plr = DoubleMLPLR(obj_dml_data,\n",
    "                              ml_l, ml_m, ml_g,\n",
    "                              n_folds=2,\n",
    "                              score='IV-type')\n",
    "    obj_dml_plr.fit()\n",
    "    theta_dml[i_rep] = obj_dml_plr.coef[0]\n",
    "    se_dml[i_rep] = obj_dml_plr.se[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2a68ee",
   "metadata": {},
   "source": [
    "# Regular OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1ca1516e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "import statsmodels.api as sm # for OLS \n",
    "# to speed up the illustration we hard-code the simulation results\n",
    "theta_ols = np.empty(n_rep)\n",
    "se_ols = np.empty(n_rep)\n",
    "# to run the full simulation uncomment the following line to fit the model for every dataset and not just for the first dataset\n",
    "for i_rep in range(n_rep):\n",
    "    (x, y, d) = data[i_rep]\n",
    "    OLS = sm.OLS(y,sm.add_constant(np.c_[d,x]))\n",
    "    results = OLS.fit()\n",
    "    theta_ols[i_rep] = results.params[1]\n",
    "    se_ols[i_rep] = results.bse[1]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "de0386ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>lwage</td>      <th>  R-squared:         </th> <td>   0.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   14.98</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 12 Dec 2022</td> <th>  Prob (F-statistic):</th> <td>1.52e-13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:20:06</td>     <th>  Log-Likelihood:    </th> <td> -433.15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   428</td>      <th>  AIC:               </th> <td>   878.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   422</td>      <th>  BIC:               </th> <td>   902.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -0.2190</td> <td>    0.300</td> <td>   -0.729</td> <td> 0.466</td> <td>   -0.809</td> <td>    0.371</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.1096</td> <td>    0.014</td> <td>    7.600</td> <td> 0.000</td> <td>    0.081</td> <td>    0.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0155</td> <td>    0.005</td> <td>    3.261</td> <td> 0.001</td> <td>    0.006</td> <td>    0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0035</td> <td>    0.005</td> <td>   -0.666</td> <td> 0.505</td> <td>   -0.014</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0755</td> <td>    0.089</td> <td>   -0.851</td> <td> 0.395</td> <td>   -0.250</td> <td>    0.099</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -0.0177</td> <td>    0.028</td> <td>   -0.632</td> <td> 0.528</td> <td>   -0.073</td> <td>    0.037</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>79.021</td> <th>  Durbin-Watson:     </th> <td>   1.985</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 299.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.773</td> <th>  Prob(JB):          </th> <td>1.04e-65</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.793</td> <th>  Cond. No.          </th> <td>    433.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  lwage   R-squared:                       0.151\n",
       "Model:                            OLS   Adj. R-squared:                  0.141\n",
       "Method:                 Least Squares   F-statistic:                     14.98\n",
       "Date:                Mon, 12 Dec 2022   Prob (F-statistic):           1.52e-13\n",
       "Time:                        10:20:06   Log-Likelihood:                -433.15\n",
       "No. Observations:                 428   AIC:                             878.3\n",
       "Df Residuals:                     422   BIC:                             902.6\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -0.2190      0.300     -0.729      0.466      -0.809       0.371\n",
       "x1             0.1096      0.014      7.600      0.000       0.081       0.138\n",
       "x2             0.0155      0.005      3.261      0.001       0.006       0.025\n",
       "x3            -0.0035      0.005     -0.666      0.505      -0.014       0.007\n",
       "x4            -0.0755      0.089     -0.851      0.395      -0.250       0.099\n",
       "x5            -0.0177      0.028     -0.632      0.528      -0.073       0.037\n",
       "==============================================================================\n",
       "Omnibus:                       79.021   Durbin-Watson:                   1.985\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              299.257\n",
       "Skew:                          -0.773   Prob(JB):                     1.04e-65\n",
       "Kurtosis:                       6.793   Cond. No.                         433.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac75834",
   "metadata": {},
   "source": [
    "# Distribution of Theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "66d67e46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+-------+------------+--------+-------+-------+--------+\n",
      "|         Estimator          | Î¸_hat | s.e(Î¸_hat) |   t    |   p   |  2.5% | 97.25% |\n",
      "+----------------------------+-------+------------+--------+-------+-------+--------+\n",
      "|            OLS             | 0.110 |   0.014    | 7.600  | 0.000 | 0.081 | 0.138  |\n",
      "|          Naive-ML          | 0.106 |   0.001    | 91.638 | 0.000 | 0.104 | 0.109  |\n",
      "|          Ortho-ML          | 0.113 |   0.009    | 12.717 | 0.000 | 0.096 | 0.130  |\n",
      "| OrthoML+Crossfitting (DML) | 0.131 |   0.023    | 5.788  | 0.000 | 0.087 | 0.176  |\n",
      "+----------------------------+-------+------------+--------+-------+-------+--------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "MC_Î¸ = np.c_[theta_ols, theta_nonorth, theta_orth_nosplit, theta_dml]\n",
    "MC_se = np.c_[se_ols, se_nonorth, se_orth_nosplit, se_dml]\n",
    "\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Estimator', 'Î¸_hat', 's.e(Î¸_hat)','t','p','2.5%','97.25%']\n",
    "a = ['OLS']+ np.c_[results.params[1], results.bse[1], results.tvalues[1], results.pvalues[1], results.conf_int(alpha=0.05, cols=None)[0][1], results.conf_int(alpha=0.05, cols=None)[1][1]].reshape(-1).tolist()\n",
    "table.add_row(a)\n",
    "a = ['Naive-ML']+ np.array(obj_dml_plr_nonorth.summary).reshape(-1).tolist()\n",
    "table.add_row(a)\n",
    "a = ['Ortho-ML']+ np.array(obj_dml_plr_orth_nosplit.summary).reshape(-1).tolist()\n",
    "table.add_row(a)\n",
    "a = ['OrthoML+Crossfitting (DML)']+ np.array(obj_dml_plr.summary).reshape(-1).tolist()\n",
    "table.add_row(a)\n",
    "table.float_format = '0.3'\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9027bc2",
   "metadata": {},
   "source": [
    "# First Stage Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d9b7a705",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "OLS_Y = LinearRegression()\n",
    "OLS_D = LinearRegression()\n",
    "RF_Y = RandomForestRegressor(n_estimators=132, max_features=12, max_depth=5, min_samples_leaf=1)\n",
    "RF_D = RandomForestRegressor(n_estimators=132, max_features=12, max_depth=5, min_samples_leaf=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a419c862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+-------+\n",
      "|    Model    |  OLS  |   RF  |\n",
      "+-------------+-------+-------+\n",
      "| Y on X (R2) | 0.034 | 0.324 |\n",
      "| D on X (R2) | 0.031 | 0.242 |\n",
      "+-------------+-------+-------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "MC_Î¸ = np.c_[theta_ols, theta_nonorth, theta_orth_nosplit, theta_dml]\n",
    "MC_se = np.c_[se_ols, se_nonorth, se_orth_nosplit, se_dml]\n",
    "\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Model', 'OLS', 'RF']\n",
    "a = ['Y on X (R2)'] + [OLS_Y.fit(x,y).score(x,y), RF_Y.fit(x,y).score(x,y)]\n",
    "table.add_row(a)\n",
    "a = ['D on X (R2)'] + [OLS_D.fit(x,d).score(x,d), RF_D.fit(x,d).score(x,d)]\n",
    "table.add_row(a)\n",
    "table.float_format = '0.3'\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dde0ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas.table.plotting import table # EDIT: see deprecation warnings below\n",
    "\n",
    "ax = plt.subplot(111, frame_on=False) # no visible frame\n",
    "ax.xaxis.set_visible(False)  # hide the x axis\n",
    "ax.yaxis.set_visible(False)  # hide the y axis\n",
    "\n",
    "table(ax, df)  # where df is your data frame\n",
    "\n",
    "plt.savefig('mytable.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf407b88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
