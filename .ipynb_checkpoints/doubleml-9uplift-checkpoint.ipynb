{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cd77248",
   "metadata": {},
   "source": [
    "# Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b68db5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13913,) (13913, 15) (13913,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from doubleml.datasets import make_plr_CCDDHNR2018, make_plr_turrell2018\n",
    "np.random.seed(1234)\n",
    "n_rep = 1\n",
    "n_obs = 10000\n",
    "n_vars = 10\n",
    "alpha = 0.5\n",
    "data = list()\n",
    "from sklearn.datasets import make_spd_matrix\n",
    "\n",
    "def g(x):\n",
    "    return np.exp(x)\n",
    "\n",
    "def m(x):\n",
    "    return np.sin(x)\n",
    "\n",
    "theta = alpha = 0.5 \n",
    "b = [1/k for k in range(1,n_vars+1)] # x weights \n",
    "sigma = make_spd_matrix(n_vars, random_state=42)\n",
    "\n",
    "for i_rep in range(n_rep):\n",
    "    df = pd.read_csv(\"/Users/pranjal/Desktop/Causal-Inference/data/penn_jae.dat\", sep = ' ')\n",
    "    outcome = 'inuidur1'\n",
    "    treatment = 'tg'\n",
    "    df['d'] = 0\n",
    "    df.loc[df.tg == 4, 'd']=1\n",
    "    treatment = 'd'\n",
    "    rest = list(df.drop([outcome, treatment, 'inuidur2','muld', 'Unnamed: 24', 'Unnamed: 25'], axis = 1).columns)\n",
    "    rest = ['female', 'black', 'othrace',\n",
    "       'dep', 'q1', 'q2', 'q3', 'q4', 'q5', 'q6', \n",
    "       'agelt35', 'agegt54', 'durable', 'lusd', 'husd']\n",
    "    df = df[[outcome] + [treatment] + rest]\n",
    "    df = df.dropna()\n",
    "    y = df[outcome]\n",
    "    d = df[treatment]\n",
    "    x = df[rest].astype('float')\n",
    "    print(y.shape, x.shape, d.shape)\n",
    "    data.append((x, y, d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27aa0664",
   "metadata": {},
   "source": [
    "# Naive ML\n",
    "- no orthogonalisation, no crossfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "58f81856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_orth_score(y, d, l_hat, m_hat, g_hat, smpls):\n",
    "    psi_a = -np.multiply(d, d)\n",
    "    psi_b = np.multiply(d, y - g_hat)\n",
    "    return psi_a, psi_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "226e7de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "================== DoubleMLData Object ==================\n",
      "\n",
      "------------------ Data summary      ------------------\n",
      "Outcome variable: y\n",
      "Treatment variable(s): ['d']\n",
      "Covariates: ['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11', 'X12', 'X13', 'X14', 'X15']\n",
      "Instrument variable(s): None\n",
      "No. Observations: 13913\n",
      "\n",
      "------------------ DataFrame info    ------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13913 entries, 0 to 13912\n",
      "Columns: 17 entries, X1 to d\n",
      "dtypes: float64(17)\n",
      "memory usage: 1.8 MB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from doubleml import DoubleMLData\n",
    "from doubleml import DoubleMLPLR\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.base import clone\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "face_colors = sns.color_palette('pastel')\n",
    "edge_colors = sns.color_palette('dark')\n",
    "np.random.seed(1111)\n",
    "ml_l = RandomForestRegressor()\n",
    "ml_m = RandomForestClassifier()\n",
    "#ml_m = LogisticRegression()\n",
    "ml_g = clone(ml_l)\n",
    "\n",
    "# to speed up the illustration we hard-code the simulation results\n",
    "theta_nonorth = np.empty(n_rep)\n",
    "se_nonorth = np.empty(n_rep)\n",
    "t_nonorth = np.empty(n_rep)\n",
    "p_nonorth = np.empty(n_rep)\n",
    "# to run the full simulation uncomment the following line to fit the model for every dataset and not just for the first dataset\n",
    "for i_rep in range(n_rep):\n",
    "    print(i_rep)\n",
    "#for i_rep in range(1):\n",
    "    (x, y, d) = data[i_rep]\n",
    "    obj_dml_data = DoubleMLData.from_arrays(x, y.ravel(), d.ravel())\n",
    "    print(obj_dml_data)\n",
    "    obj_dml_plr_nonorth = DoubleMLPLR(obj_dml_data,\n",
    "                                      ml_l, ml_m, ml_g,\n",
    "                                      n_folds=1,\n",
    "                                      apply_cross_fitting=False,\n",
    "                                      score=non_orth_score)\n",
    "    obj_dml_plr_nonorth.fit()\n",
    "    theta_nonorth[i_rep] = obj_dml_plr_nonorth.coef[0]\n",
    "    se_nonorth[i_rep] = obj_dml_plr_nonorth.se[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c563855",
   "metadata": {},
   "source": [
    "# Orthogonal Machine Learning\n",
    "- resolves regularization bias, but not overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f2682d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2222)\n",
    "# to speed up the illustration we hard-code the simulation results\n",
    "theta_orth_nosplit = np.empty(n_rep)\n",
    "se_orth_nosplit = np.empty(n_rep)\n",
    "# to run the full simulation uncomment the following line to fit the model for every dataset and not just for the first dataset\n",
    "for i_rep in range(n_rep):\n",
    "    print(i_rep)\n",
    "#for i_rep in range(1):\n",
    "    (x, y, d) = data[i_rep]\n",
    "    obj_dml_data = DoubleMLData.from_arrays(x, y, d)\n",
    "    obj_dml_plr_orth_nosplit = DoubleMLPLR(obj_dml_data,\n",
    "                                           ml_l, ml_m, ml_g,\n",
    "                                           n_folds=1,\n",
    "                                           score='IV-type',\n",
    "                                           apply_cross_fitting=False)\n",
    "    obj_dml_plr_orth_nosplit.fit()\n",
    "    theta_orth_nosplit[i_rep] = obj_dml_plr_orth_nosplit.coef[0]\n",
    "    se_orth_nosplit[i_rep] = obj_dml_plr_orth_nosplit.se[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa0e04f",
   "metadata": {},
   "source": [
    "# Orthogonal ML + Cross fitting (DML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1da32ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "# to speed up the illustration we hard-code the simulation results\n",
    "theta_dml = np.empty(n_rep)\n",
    "se_dml = np.empty(n_rep)\n",
    "\n",
    "# to run the full simulation uncomment the following line to fit the model for every dataset and not just for the first dataset\n",
    "for i_rep in range(n_rep):\n",
    "    print(i_rep)\n",
    "    (x, y, d) = data[i_rep]\n",
    "    obj_dml_data = DoubleMLData.from_arrays(x, y, d)\n",
    "    obj_dml_plr = DoubleMLPLR(obj_dml_data,\n",
    "                              ml_l, ml_m, ml_g,\n",
    "                              n_folds=2,\n",
    "                              score='IV-type')\n",
    "    obj_dml_plr.fit()\n",
    "    theta_dml[i_rep] = obj_dml_plr.coef[0]\n",
    "    se_dml[i_rep] = obj_dml_plr.se[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2a68ee",
   "metadata": {},
   "source": [
    "# Regular OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1ca1516e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "import statsmodels.api as sm # for OLS \n",
    "# to speed up the illustration we hard-code the simulation results\n",
    "theta_ols = np.empty(n_rep)\n",
    "se_ols = np.empty(n_rep)\n",
    "# to run the full simulation uncomment the following line to fit the model for every dataset and not just for the first dataset\n",
    "for i_rep in range(n_rep):\n",
    "    (x, y, d) = data[i_rep]\n",
    "    OLS = sm.OLS(y,sm.add_constant(np.c_[d,x]))\n",
    "    results = OLS.fit()\n",
    "    theta_ols[i_rep] = results.params[1]\n",
    "    se_ols[i_rep] = results.bse[1]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fd05020c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>inuidur1</td>     <th>  R-squared:         </th> <td>   0.029</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.028</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   26.04</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 12 Dec 2022</td> <th>  Prob (F-statistic):</th> <td>2.13e-77</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:33:29</td>     <th>  Log-Likelihood:    </th> <td> -52348.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 13913</td>      <th>  AIC:               </th> <td>1.047e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 13896</td>      <th>  BIC:               </th> <td>1.049e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    16</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   11.1668</td> <td>    0.256</td> <td>   43.549</td> <td> 0.000</td> <td>   10.664</td> <td>   11.669</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.3713</td> <td>    0.267</td> <td>   -1.389</td> <td> 0.165</td> <td>   -0.895</td> <td>    0.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    1.2573</td> <td>    0.183</td> <td>    6.857</td> <td> 0.000</td> <td>    0.898</td> <td>    1.617</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -1.7531</td> <td>    0.288</td> <td>   -6.086</td> <td> 0.000</td> <td>   -2.318</td> <td>   -1.188</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -1.9133</td> <td>    1.172</td> <td>   -1.632</td> <td> 0.103</td> <td>   -4.211</td> <td>    0.384</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.4130</td> <td>    0.118</td> <td>    3.510</td> <td> 0.000</td> <td>    0.182</td> <td>    0.644</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.2144</td> <td>    0.799</td> <td>    0.268</td> <td> 0.788</td> <td>   -1.351</td> <td>    1.780</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.6395</td> <td>    0.271</td> <td>    2.362</td> <td> 0.018</td> <td>    0.109</td> <td>    1.170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -0.1060</td> <td>    0.259</td> <td>   -0.410</td> <td> 0.682</td> <td>   -0.613</td> <td>    0.401</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>   -0.1246</td> <td>    0.261</td> <td>   -0.478</td> <td> 0.632</td> <td>   -0.635</td> <td>    0.386</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>    2.0250</td> <td>    0.368</td> <td>    5.502</td> <td> 0.000</td> <td>    1.304</td> <td>    2.746</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    0.7024</td> <td>    0.290</td> <td>    2.420</td> <td> 0.016</td> <td>    0.134</td> <td>    1.271</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>    4.0874</td> <td>    0.288</td> <td>   14.175</td> <td> 0.000</td> <td>    3.522</td> <td>    4.653</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>    0.3841</td> <td>    0.255</td> <td>    1.504</td> <td> 0.133</td> <td>   -0.117</td> <td>    0.885</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>   -1.8957</td> <td>    0.288</td> <td>   -6.577</td> <td> 0.000</td> <td>   -2.461</td> <td>   -1.331</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>    0.6212</td> <td>    0.247</td> <td>    2.513</td> <td> 0.012</td> <td>    0.137</td> <td>    1.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>    1.3349</td> <td>    0.208</td> <td>    6.417</td> <td> 0.000</td> <td>    0.927</td> <td>    1.743</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>3261.871</td> <th>  Durbin-Watson:     </th> <td>   1.967</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1024.029</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 0.450</td>  <th>  Prob(JB):          </th> <td>4.31e-223</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 2.022</td>  <th>  Cond. No.          </th> <td>    18.6</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:               inuidur1   R-squared:                       0.029\n",
       "Model:                            OLS   Adj. R-squared:                  0.028\n",
       "Method:                 Least Squares   F-statistic:                     26.04\n",
       "Date:                Mon, 12 Dec 2022   Prob (F-statistic):           2.13e-77\n",
       "Time:                        10:33:29   Log-Likelihood:                -52348.\n",
       "No. Observations:               13913   AIC:                         1.047e+05\n",
       "Df Residuals:                   13896   BIC:                         1.049e+05\n",
       "Df Model:                          16                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         11.1668      0.256     43.549      0.000      10.664      11.669\n",
       "x1            -0.3713      0.267     -1.389      0.165      -0.895       0.153\n",
       "x2             1.2573      0.183      6.857      0.000       0.898       1.617\n",
       "x3            -1.7531      0.288     -6.086      0.000      -2.318      -1.188\n",
       "x4            -1.9133      1.172     -1.632      0.103      -4.211       0.384\n",
       "x5             0.4130      0.118      3.510      0.000       0.182       0.644\n",
       "x6             0.2144      0.799      0.268      0.788      -1.351       1.780\n",
       "x7             0.6395      0.271      2.362      0.018       0.109       1.170\n",
       "x8            -0.1060      0.259     -0.410      0.682      -0.613       0.401\n",
       "x9            -0.1246      0.261     -0.478      0.632      -0.635       0.386\n",
       "x10            2.0250      0.368      5.502      0.000       1.304       2.746\n",
       "x11            0.7024      0.290      2.420      0.016       0.134       1.271\n",
       "x12            4.0874      0.288     14.175      0.000       3.522       4.653\n",
       "x13            0.3841      0.255      1.504      0.133      -0.117       0.885\n",
       "x14           -1.8957      0.288     -6.577      0.000      -2.461      -1.331\n",
       "x15            0.6212      0.247      2.513      0.012       0.137       1.106\n",
       "x16            1.3349      0.208      6.417      0.000       0.927       1.743\n",
       "==============================================================================\n",
       "Omnibus:                     3261.871   Durbin-Watson:                   1.967\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1024.029\n",
       "Skew:                           0.450   Prob(JB):                    4.31e-223\n",
       "Kurtosis:                       2.022   Cond. No.                         18.6\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac75834",
   "metadata": {},
   "source": [
    "# Distribution of Theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "66d67e46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+--------+------------+--------+-------+--------+--------+\n",
      "|         Estimator          | θ_hat  | s.e(θ_hat) |   t    |   p   |  2.5%  | 97.25% |\n",
      "+----------------------------+--------+------------+--------+-------+--------+--------+\n",
      "|            OLS             | -0.371 |   0.267    | -1.389 | 0.165 | -0.895 | 0.153  |\n",
      "|          Naive-ML          | -0.333 |   0.236    | -1.412 | 0.158 | -0.796 | 0.129  |\n",
      "|          Ortho-ML          | -0.352 |   0.262    | -1.343 | 0.179 | -0.865 | 0.162  |\n",
      "| OrthoML+Crossfitting (DML) | -0.606 |   0.289    | -2.101 | 0.036 | -1.172 | -0.041 |\n",
      "+----------------------------+--------+------------+--------+-------+--------+--------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "MC_θ = np.c_[theta_ols, theta_nonorth, theta_orth_nosplit, theta_dml]\n",
    "MC_se = np.c_[se_ols, se_nonorth, se_orth_nosplit, se_dml]\n",
    "\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Estimator', 'θ_hat', 's.e(θ_hat)','t','p','2.5%','97.25%']\n",
    "a = ['OLS']+ np.c_[results.params[1], results.bse[1], results.tvalues[1], results.pvalues[1], results.conf_int(alpha=0.05, cols=None)[0][1], results.conf_int(alpha=0.05, cols=None)[1][1]].reshape(-1).tolist()\n",
    "table.add_row(a)\n",
    "a = ['Naive-ML']+ np.array(obj_dml_plr_nonorth.summary).reshape(-1).tolist()\n",
    "table.add_row(a)\n",
    "a = ['Ortho-ML']+ np.array(obj_dml_plr_orth_nosplit.summary).reshape(-1).tolist()\n",
    "table.add_row(a)\n",
    "a = ['OrthoML+Crossfitting (DML)']+ np.array(obj_dml_plr.summary).reshape(-1).tolist()\n",
    "table.add_row(a)\n",
    "table.float_format = '0.3'\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9027bc2",
   "metadata": {},
   "source": [
    "# First Stage Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d9b7a705",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "OLS_Y = LinearRegression()\n",
    "OLS_D = LogisticRegression()\n",
    "RF_Y = RandomForestRegressor()\n",
    "RF_D = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a419c862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+-------+\n",
      "|       Model       |  OLS  |   RF  |\n",
      "+-------------------+-------+-------+\n",
      "|    Y on X (R2)    | 0.029 | 0.103 |\n",
      "| D on X (Accuracy) | 0.875 | 0.878 |\n",
      "+-------------------+-------+-------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "MC_θ = np.c_[theta_ols, theta_nonorth, theta_orth_nosplit, theta_dml]\n",
    "MC_se = np.c_[se_ols, se_nonorth, se_orth_nosplit, se_dml]\n",
    "\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Model', 'OLS', 'RF']\n",
    "a = ['Y on X (R2)'] + [OLS_Y.fit(x,y).score(x,y), RF_Y.fit(x,y).score(x,y)]\n",
    "table.add_row(a)\n",
    "a = ['D on X (Accuracy)'] + [OLS_D.fit(x,d).score(x,d), RF_D.fit(x,d).score(x,d)]\n",
    "table.add_row(a)\n",
    "table.float_format = '0.3'\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dde0ce6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf407b88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
