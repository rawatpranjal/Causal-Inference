{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cd77248",
   "metadata": {},
   "source": [
    "# Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b68db5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from doubleml.datasets import make_plr_CCDDHNR2018, make_plr_turrell2018\n",
    "np.random.seed(1234)\n",
    "n_rep = 1\n",
    "n_obs = 10000\n",
    "n_vars = 10\n",
    "alpha = 0.5\n",
    "data = list()\n",
    "from sklearn.datasets import make_spd_matrix\n",
    "\n",
    "def g(x):\n",
    "    return np.exp(x)\n",
    "\n",
    "def m(x):\n",
    "    return np.sin(x)\n",
    "\n",
    "theta = alpha = 0.5 \n",
    "b = [1/k for k in range(1,n_vars+1)] # x weights \n",
    "sigma = make_spd_matrix(n_vars, random_state=42)\n",
    "\n",
    "for i_rep in range(n_rep):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    df = pd.read_csv('/Users/pranjal/Desktop/Causal-Inference/data/wage.csv')\n",
    "    cat = df.select_dtypes('object').columns\n",
    "    df = pd.get_dummies(df, columns = cat, drop_first = True)\n",
    "    outcome = 'lwage'\n",
    "    treatment = 'educ'\n",
    "    #rest = list(df.drop([outcome, treatment], axis = 1).columns)\n",
    "    rest = ['exper','age', 'kidslt6', 'kidsge6']\n",
    "    df = df[[outcome] + [treatment] + rest]\n",
    "    df = df.dropna()\n",
    "    y = df[outcome]\n",
    "    d = df[treatment]\n",
    "    x = df[rest].astype('float')\n",
    "    data.append((x, y, d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27aa0664",
   "metadata": {},
   "source": [
    "# Naive ML\n",
    "- no orthogonalisation, no crossfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58f81856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_orth_score(y, d, l_hat, m_hat, g_hat, smpls):\n",
    "    psi_a = -np.multiply(d, d)\n",
    "    psi_b = np.multiply(d, y - g_hat)\n",
    "    return psi_a, psi_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "226e7de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "================== DoubleMLData Object ==================\n",
      "\n",
      "------------------ Data summary      ------------------\n",
      "Outcome variable: y\n",
      "Treatment variable(s): ['d']\n",
      "Covariates: ['X1', 'X2', 'X3', 'X4']\n",
      "Instrument variable(s): None\n",
      "No. Observations: 428\n",
      "\n",
      "------------------ DataFrame info    ------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 428 entries, 0 to 427\n",
      "Columns: 6 entries, X1 to d\n",
      "dtypes: float64(6)\n",
      "memory usage: 20.2 KB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from doubleml import DoubleMLData\n",
    "from doubleml import DoubleMLPLR\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.base import clone\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "face_colors = sns.color_palette('pastel')\n",
    "edge_colors = sns.color_palette('dark')\n",
    "np.random.seed(1111)\n",
    "ml_l = RandomForestRegressor(n_estimators=132, max_features=12, max_depth=5, min_samples_leaf=1)\n",
    "ml_m = RandomForestRegressor(n_estimators=132, max_features=12, max_depth=5, min_samples_leaf=1)\n",
    "#ml_m = LogisticRegression()\n",
    "ml_g = clone(ml_l)\n",
    "\n",
    "# to speed up the illustration we hard-code the simulation results\n",
    "theta_nonorth = np.empty(n_rep)\n",
    "se_nonorth = np.empty(n_rep)\n",
    "t_nonorth = np.empty(n_rep)\n",
    "p_nonorth = np.empty(n_rep)\n",
    "# to run the full simulation uncomment the following line to fit the model for every dataset and not just for the first dataset\n",
    "for i_rep in range(n_rep):\n",
    "    print(i_rep)\n",
    "#for i_rep in range(1):\n",
    "    (x, y, d) = data[i_rep]\n",
    "    obj_dml_data = DoubleMLData.from_arrays(x, y.ravel(), d.ravel())\n",
    "    print(obj_dml_data)\n",
    "    obj_dml_plr_nonorth = DoubleMLPLR(obj_dml_data,\n",
    "                                      ml_l, ml_m, ml_g,\n",
    "                                      n_folds=1,\n",
    "                                      apply_cross_fitting=False,\n",
    "                                      score=non_orth_score)\n",
    "    obj_dml_plr_nonorth.fit()\n",
    "    theta_nonorth[i_rep] = obj_dml_plr_nonorth.coef[0]\n",
    "    se_nonorth[i_rep] = obj_dml_plr_nonorth.se[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c563855",
   "metadata": {},
   "source": [
    "# Orthogonal Machine Learning\n",
    "- resolves regularization bias, but not overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2682d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2222)\n",
    "# to speed up the illustration we hard-code the simulation results\n",
    "theta_orth_nosplit = np.empty(n_rep)\n",
    "se_orth_nosplit = np.empty(n_rep)\n",
    "# to run the full simulation uncomment the following line to fit the model for every dataset and not just for the first dataset\n",
    "for i_rep in range(n_rep):\n",
    "    print(i_rep)\n",
    "#for i_rep in range(1):\n",
    "    (x, y, d) = data[i_rep]\n",
    "    obj_dml_data = DoubleMLData.from_arrays(x, y, d)\n",
    "    obj_dml_plr_orth_nosplit = DoubleMLPLR(obj_dml_data,\n",
    "                                           ml_l, ml_m, ml_g,\n",
    "                                           n_folds=1,\n",
    "                                           score='IV-type',\n",
    "                                           apply_cross_fitting=False)\n",
    "    obj_dml_plr_orth_nosplit.fit()\n",
    "    theta_orth_nosplit[i_rep] = obj_dml_plr_orth_nosplit.coef[0]\n",
    "    se_orth_nosplit[i_rep] = obj_dml_plr_orth_nosplit.se[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa0e04f",
   "metadata": {},
   "source": [
    "# Orthogonal ML + Cross fitting (DML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1da32ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "# to speed up the illustration we hard-code the simulation results\n",
    "theta_dml = np.empty(n_rep)\n",
    "se_dml = np.empty(n_rep)\n",
    "\n",
    "# to run the full simulation uncomment the following line to fit the model for every dataset and not just for the first dataset\n",
    "for i_rep in range(n_rep):\n",
    "    print(i_rep)\n",
    "    (x, y, d) = data[i_rep]\n",
    "    obj_dml_data = DoubleMLData.from_arrays(x, y, d)\n",
    "    obj_dml_plr = DoubleMLPLR(obj_dml_data,\n",
    "                              ml_l, ml_m, ml_g,\n",
    "                              n_folds=2,\n",
    "                              score='IV-type')\n",
    "    obj_dml_plr.fit()\n",
    "    theta_dml[i_rep] = obj_dml_plr.coef[0]\n",
    "    se_dml[i_rep] = obj_dml_plr.se[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2a68ee",
   "metadata": {},
   "source": [
    "# Regular OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1ca1516e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "import statsmodels.api as sm # for OLS \n",
    "# to speed up the illustration we hard-code the simulation results\n",
    "theta_ols = np.empty(n_rep)\n",
    "se_ols = np.empty(n_rep)\n",
    "# to run the full simulation uncomment the following line to fit the model for every dataset and not just for the first dataset\n",
    "for i_rep in range(n_rep):\n",
    "    (x, y, d) = data[i_rep]\n",
    "    OLS = sm.OLS(y,sm.add_constant(np.c_[d,x]))\n",
    "    results = OLS.fit()\n",
    "    theta_ols[i_rep] = results.params[1]\n",
    "    se_ols[i_rep] = results.bse[1]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fd05020c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>lwage</td>      <th>  R-squared:         </th> <td>   0.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   14.98</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 12 Dec 2022</td> <th>  Prob (F-statistic):</th> <td>1.52e-13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>09:55:35</td>     <th>  Log-Likelihood:    </th> <td> -433.15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   428</td>      <th>  AIC:               </th> <td>   878.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   422</td>      <th>  BIC:               </th> <td>   902.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -0.2190</td> <td>    0.300</td> <td>   -0.729</td> <td> 0.466</td> <td>   -0.809</td> <td>    0.371</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.1096</td> <td>    0.014</td> <td>    7.600</td> <td> 0.000</td> <td>    0.081</td> <td>    0.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0155</td> <td>    0.005</td> <td>    3.261</td> <td> 0.001</td> <td>    0.006</td> <td>    0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0035</td> <td>    0.005</td> <td>   -0.666</td> <td> 0.505</td> <td>   -0.014</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0755</td> <td>    0.089</td> <td>   -0.851</td> <td> 0.395</td> <td>   -0.250</td> <td>    0.099</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -0.0177</td> <td>    0.028</td> <td>   -0.632</td> <td> 0.528</td> <td>   -0.073</td> <td>    0.037</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>79.021</td> <th>  Durbin-Watson:     </th> <td>   1.985</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 299.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.773</td> <th>  Prob(JB):          </th> <td>1.04e-65</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.793</td> <th>  Cond. No.          </th> <td>    433.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  lwage   R-squared:                       0.151\n",
       "Model:                            OLS   Adj. R-squared:                  0.141\n",
       "Method:                 Least Squares   F-statistic:                     14.98\n",
       "Date:                Mon, 12 Dec 2022   Prob (F-statistic):           1.52e-13\n",
       "Time:                        09:55:35   Log-Likelihood:                -433.15\n",
       "No. Observations:                 428   AIC:                             878.3\n",
       "Df Residuals:                     422   BIC:                             902.6\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -0.2190      0.300     -0.729      0.466      -0.809       0.371\n",
       "x1             0.1096      0.014      7.600      0.000       0.081       0.138\n",
       "x2             0.0155      0.005      3.261      0.001       0.006       0.025\n",
       "x3            -0.0035      0.005     -0.666      0.505      -0.014       0.007\n",
       "x4            -0.0755      0.089     -0.851      0.395      -0.250       0.099\n",
       "x5            -0.0177      0.028     -0.632      0.528      -0.073       0.037\n",
       "==============================================================================\n",
       "Omnibus:                       79.021   Durbin-Watson:                   1.985\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              299.257\n",
       "Skew:                          -0.773   Prob(JB):                     1.04e-65\n",
       "Kurtosis:                       6.793   Cond. No.                         433.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac75834",
   "metadata": {},
   "source": [
    "# Distribution of Theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "66d67e46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+-------+------------+--------+-------+-------+--------+\n",
      "|         Estimator          | θ_hat | s.e(θ_hat) |   t    |   p   |  2.5% | 97.25% |\n",
      "+----------------------------+-------+------------+--------+-------+-------+--------+\n",
      "|            OLS             | 0.110 |   0.014    | 7.600  | 0.000 | 0.081 | 0.138  |\n",
      "|          Naive-ML          | 0.110 |   0.002    | 51.678 | 0.000 | 0.105 | 0.114  |\n",
      "|          Ortho-ML          | 0.109 |   0.012    | 9.011  | 0.000 | 0.085 | 0.133  |\n",
      "| OrthoML+Crossfitting (DML) | 0.119 |   0.016    | 7.295  | 0.000 | 0.087 | 0.151  |\n",
      "+----------------------------+-------+------------+--------+-------+-------+--------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "MC_θ = np.c_[theta_ols, theta_nonorth, theta_orth_nosplit, theta_dml]\n",
    "MC_se = np.c_[se_ols, se_nonorth, se_orth_nosplit, se_dml]\n",
    "\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Estimator', 'θ_hat', 's.e(θ_hat)','t','p','2.5%','97.25%']\n",
    "a = ['OLS']+ np.c_[results.params[1], results.bse[1], results.tvalues[1], results.pvalues[1], results.conf_int(alpha=0.05, cols=None)[0][1], results.conf_int(alpha=0.05, cols=None)[1][1]].reshape(-1).tolist()\n",
    "table.add_row(a)\n",
    "a = ['Naive-ML']+ np.array(obj_dml_plr_nonorth.summary).reshape(-1).tolist()\n",
    "table.add_row(a)\n",
    "a = ['Ortho-ML']+ np.array(obj_dml_plr_orth_nosplit.summary).reshape(-1).tolist()\n",
    "table.add_row(a)\n",
    "a = ['OrthoML+Crossfitting (DML)']+ np.array(obj_dml_plr.summary).reshape(-1).tolist()\n",
    "table.add_row(a)\n",
    "table.float_format = '0.3'\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9027bc2",
   "metadata": {},
   "source": [
    "# First Stage Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d9b7a705",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "OLS_Y = LinearRegression()\n",
    "OLS_D = LinearRegression()\n",
    "RF_Y = RandomForestRegressor(n_estimators=132, max_features=12, max_depth=5, min_samples_leaf=1)\n",
    "RF_D = RandomForestClassifier(n_estimators=132, max_features=12, max_depth=5, min_samples_leaf=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a419c862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+-------+\n",
      "|    Model    |  OLS  |   RF  |\n",
      "+-------------+-------+-------+\n",
      "| Y on X (R2) | 0.034 | 0.324 |\n",
      "| D on X (R2) | 0.031 | 0.533 |\n",
      "+-------------+-------+-------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "MC_θ = np.c_[theta_ols, theta_nonorth, theta_orth_nosplit, theta_dml]\n",
    "MC_se = np.c_[se_ols, se_nonorth, se_orth_nosplit, se_dml]\n",
    "\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Model', 'OLS', 'RF']\n",
    "a = ['Y on X (R2)'] + [OLS_Y.fit(x,y).score(x,y), RF_Y.fit(x,y).score(x,y)]\n",
    "table.add_row(a)\n",
    "a = ['D on X (R2)'] + [OLS_D.fit(x,d).score(x,d), RF_D.fit(x,d).score(x,d)]\n",
    "table.add_row(a)\n",
    "table.float_format = '0.3'\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dde0ce6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf407b88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
