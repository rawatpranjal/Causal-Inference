{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cd77248",
   "metadata": {},
   "source": [
    "# Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1393378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025837</th>\n",
       "      <td>23.646673</td>\n",
       "      <td>10.059654</td>\n",
       "      <td>8.214383</td>\n",
       "      <td>4.679882</td>\n",
       "      <td>10.280525</td>\n",
       "      <td>4.115453</td>\n",
       "      <td>-8.058865</td>\n",
       "      <td>4.833815</td>\n",
       "      <td>3.971858</td>\n",
       "      <td>13.190056</td>\n",
       "      <td>5.300375</td>\n",
       "      <td>-0.168679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9957958</th>\n",
       "      <td>25.981476</td>\n",
       "      <td>10.059654</td>\n",
       "      <td>9.004356</td>\n",
       "      <td>4.679882</td>\n",
       "      <td>10.280525</td>\n",
       "      <td>4.115453</td>\n",
       "      <td>-3.282109</td>\n",
       "      <td>4.833815</td>\n",
       "      <td>3.920995</td>\n",
       "      <td>13.190056</td>\n",
       "      <td>5.300375</td>\n",
       "      <td>-0.168679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10636458</th>\n",
       "      <td>12.616365</td>\n",
       "      <td>10.059654</td>\n",
       "      <td>8.644269</td>\n",
       "      <td>4.679882</td>\n",
       "      <td>10.280525</td>\n",
       "      <td>4.115453</td>\n",
       "      <td>0.294443</td>\n",
       "      <td>4.833815</td>\n",
       "      <td>3.927254</td>\n",
       "      <td>21.416100</td>\n",
       "      <td>5.300375</td>\n",
       "      <td>-0.168679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13657104</th>\n",
       "      <td>14.386771</td>\n",
       "      <td>10.059654</td>\n",
       "      <td>8.214383</td>\n",
       "      <td>0.294543</td>\n",
       "      <td>10.280525</td>\n",
       "      <td>1.128518</td>\n",
       "      <td>-11.495164</td>\n",
       "      <td>11.685624</td>\n",
       "      <td>3.971858</td>\n",
       "      <td>13.190056</td>\n",
       "      <td>5.300375</td>\n",
       "      <td>-0.168679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6991145</th>\n",
       "      <td>12.616365</td>\n",
       "      <td>10.059654</td>\n",
       "      <td>8.587777</td>\n",
       "      <td>4.679882</td>\n",
       "      <td>10.280525</td>\n",
       "      <td>4.115453</td>\n",
       "      <td>0.294443</td>\n",
       "      <td>4.833815</td>\n",
       "      <td>3.955396</td>\n",
       "      <td>16.226044</td>\n",
       "      <td>5.300375</td>\n",
       "      <td>-0.168679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 f0         f1        f2        f3         f4        f5  \\\n",
       "2025837   23.646673  10.059654  8.214383  4.679882  10.280525  4.115453   \n",
       "9957958   25.981476  10.059654  9.004356  4.679882  10.280525  4.115453   \n",
       "10636458  12.616365  10.059654  8.644269  4.679882  10.280525  4.115453   \n",
       "13657104  14.386771  10.059654  8.214383  0.294543  10.280525  1.128518   \n",
       "6991145   12.616365  10.059654  8.587777  4.679882  10.280525  4.115453   \n",
       "\n",
       "                 f6         f7        f8         f9       f10       f11  \n",
       "2025837   -8.058865   4.833815  3.971858  13.190056  5.300375 -0.168679  \n",
       "9957958   -3.282109   4.833815  3.920995  13.190056  5.300375 -0.168679  \n",
       "10636458   0.294443   4.833815  3.927254  21.416100  5.300375 -0.168679  \n",
       "13657104 -11.495164  11.685624  3.971858  13.190056  5.300375 -0.168679  \n",
       "6991145    0.294443   4.833815  3.955396  16.226044  5.300375 -0.168679  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('/Users/pranjal/Downloads/criteo-uplift-v2.1.csv')\n",
    "df = df.sample(100000)\n",
    "outcome = 'visit'\n",
    "treatment = 'treatment'\n",
    "rest = list(df.drop([outcome, treatment, 'exposure', 'conversion'], axis = 1).columns)\n",
    "#rest = ['exper','age', 'kidslt6', 'kidsge6']\n",
    "df = df[[outcome] + [treatment] + rest]\n",
    "#df = df.dropna()\n",
    "#df = df.fillna(0)\n",
    "#df = df[df.avg <= 15]\n",
    "y = df[outcome]\n",
    "d = df[treatment]\n",
    "x = df[rest].astype('float')\n",
    "print(df.shape)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b68db5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000,) (100000, 12) (100000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from doubleml.datasets import make_plr_CCDDHNR2018, make_plr_turrell2018\n",
    "np.random.seed(1234)\n",
    "n_rep = 1\n",
    "n_obs = 10000\n",
    "n_vars = 10\n",
    "alpha = 0.5\n",
    "data = list()\n",
    "from sklearn.datasets import make_spd_matrix\n",
    "\n",
    "def g(x):\n",
    "    return np.exp(x)\n",
    "\n",
    "def m(x):\n",
    "    return np.sin(x)\n",
    "\n",
    "theta = alpha = 0.5 \n",
    "b = [1/k for k in range(1,n_vars+1)] # x weights \n",
    "sigma = make_spd_matrix(n_vars, random_state=42)\n",
    "\n",
    "for i_rep in range(n_rep):\n",
    "    print(y.shape, x.shape, d.shape)\n",
    "    data.append((x, y, d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27aa0664",
   "metadata": {},
   "source": [
    "# Naive ML\n",
    "- no orthogonalisation, no crossfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58f81856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_orth_score(y, d, l_hat, m_hat, g_hat, smpls):\n",
    "    psi_a = -np.multiply(d, d)\n",
    "    psi_b = np.multiply(d, y - g_hat)\n",
    "    return psi_a, psi_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "226e7de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "================== DoubleMLData Object ==================\n",
      "\n",
      "------------------ Data summary      ------------------\n",
      "Outcome variable: y\n",
      "Treatment variable(s): ['d']\n",
      "Covariates: ['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11', 'X12']\n",
      "Instrument variable(s): None\n",
      "No. Observations: 100000\n",
      "\n",
      "------------------ DataFrame info    ------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Columns: 14 entries, X1 to d\n",
      "dtypes: float64(14)\n",
      "memory usage: 10.7 MB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from doubleml import DoubleMLData\n",
    "from doubleml import DoubleMLPLR\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.base import clone\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "face_colors = sns.color_palette('pastel')\n",
    "edge_colors = sns.color_palette('dark')\n",
    "np.random.seed(1111)\n",
    "ml_l = RandomForestRegressor()\n",
    "ml_m = RandomForestClassifier()\n",
    "#ml_m = LogisticRegression()\n",
    "ml_g = clone(ml_l)\n",
    "\n",
    "# to speed up the illustration we hard-code the simulation results\n",
    "theta_nonorth = np.empty(n_rep)\n",
    "se_nonorth = np.empty(n_rep)\n",
    "t_nonorth = np.empty(n_rep)\n",
    "p_nonorth = np.empty(n_rep)\n",
    "# to run the full simulation uncomment the following line to fit the model for every dataset and not just for the first dataset\n",
    "for i_rep in range(n_rep):\n",
    "    print(i_rep)\n",
    "#for i_rep in range(1):\n",
    "    (x, y, d) = data[i_rep]\n",
    "    obj_dml_data = DoubleMLData.from_arrays(x, y.ravel(), d.ravel())\n",
    "    print(obj_dml_data)\n",
    "    obj_dml_plr_nonorth = DoubleMLPLR(obj_dml_data,\n",
    "                                      ml_l, ml_m, ml_g,\n",
    "                                      n_folds=1,\n",
    "                                      apply_cross_fitting=False,\n",
    "                                      score=non_orth_score)\n",
    "    obj_dml_plr_nonorth.fit()\n",
    "    theta_nonorth[i_rep] = obj_dml_plr_nonorth.coef[0]\n",
    "    se_nonorth[i_rep] = obj_dml_plr_nonorth.se[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c563855",
   "metadata": {},
   "source": [
    "# Orthogonal Machine Learning\n",
    "- resolves regularization bias, but not overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2682d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2222)\n",
    "# to speed up the illustration we hard-code the simulation results\n",
    "theta_orth_nosplit = np.empty(n_rep)\n",
    "se_orth_nosplit = np.empty(n_rep)\n",
    "# to run the full simulation uncomment the following line to fit the model for every dataset and not just for the first dataset\n",
    "for i_rep in range(n_rep):\n",
    "    print(i_rep)\n",
    "#for i_rep in range(1):\n",
    "    (x, y, d) = data[i_rep]\n",
    "    obj_dml_data = DoubleMLData.from_arrays(x, y, d)\n",
    "    obj_dml_plr_orth_nosplit = DoubleMLPLR(obj_dml_data,\n",
    "                                           ml_l, ml_m, ml_g,\n",
    "                                           n_folds=1,\n",
    "                                           score='IV-type',\n",
    "                                           apply_cross_fitting=False)\n",
    "    obj_dml_plr_orth_nosplit.fit()\n",
    "    theta_orth_nosplit[i_rep] = obj_dml_plr_orth_nosplit.coef[0]\n",
    "    se_orth_nosplit[i_rep] = obj_dml_plr_orth_nosplit.se[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa0e04f",
   "metadata": {},
   "source": [
    "# Orthogonal ML + Cross fitting (DML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1da32ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "# to speed up the illustration we hard-code the simulation results\n",
    "theta_dml = np.empty(n_rep)\n",
    "se_dml = np.empty(n_rep)\n",
    "\n",
    "# to run the full simulation uncomment the following line to fit the model for every dataset and not just for the first dataset\n",
    "for i_rep in range(n_rep):\n",
    "    print(i_rep)\n",
    "    (x, y, d) = data[i_rep]\n",
    "    obj_dml_data = DoubleMLData.from_arrays(x, y, d)\n",
    "    obj_dml_plr = DoubleMLPLR(obj_dml_data,\n",
    "                              ml_l, ml_m, ml_g,\n",
    "                              n_folds=2,\n",
    "                              score='IV-type')\n",
    "    obj_dml_plr.fit()\n",
    "    theta_dml[i_rep] = obj_dml_plr.coef[0]\n",
    "    se_dml[i_rep] = obj_dml_plr.se[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2a68ee",
   "metadata": {},
   "source": [
    "# Regular OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ca1516e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "import statsmodels.api as sm # for OLS \n",
    "# to speed up the illustration we hard-code the simulation results\n",
    "theta_ols = np.empty(n_rep)\n",
    "se_ols = np.empty(n_rep)\n",
    "# to run the full simulation uncomment the following line to fit the model for every dataset and not just for the first dataset\n",
    "for i_rep in range(n_rep):\n",
    "    (x, y, d) = data[i_rep]\n",
    "    OLS = sm.OLS(y,sm.add_constant(np.c_[d,x]))\n",
    "    results = OLS.fit()\n",
    "    theta_ols[i_rep] = results.params[1]\n",
    "    se_ols[i_rep] = results.bse[1]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd05020c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>visit</td>      <th>  R-squared:         </th>  <td>   0.278</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.278</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   2968.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 12 Dec 2022</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:51:13</td>     <th>  Log-Likelihood:    </th>  <td>  30879.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>100000</td>      <th>  AIC:               </th> <td>-6.173e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 99986</td>      <th>  BIC:               </th> <td>-6.160e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    4.6387</td> <td>    0.139</td> <td>   33.426</td> <td> 0.000</td> <td>    4.367</td> <td>    4.911</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.0040</td> <td>    0.002</td> <td>    2.534</td> <td> 0.011</td> <td>    0.001</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.0005</td> <td>    0.000</td> <td>   -3.427</td> <td> 0.001</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0078</td> <td>    0.008</td> <td>   -1.021</td> <td> 0.307</td> <td>   -0.023</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0895</td> <td>    0.003</td> <td>  -31.384</td> <td> 0.000</td> <td>   -0.095</td> <td>   -0.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -0.0012</td> <td>    0.001</td> <td>   -1.973</td> <td> 0.049</td> <td>   -0.002</td> <td>-8.07e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.0351</td> <td>    0.003</td> <td>   10.312</td> <td> 0.000</td> <td>    0.028</td> <td>    0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>   -0.0080</td> <td>    0.003</td> <td>   -2.893</td> <td> 0.004</td> <td>   -0.013</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -0.0018</td> <td>    0.000</td> <td>   -9.964</td> <td> 0.000</td> <td>   -0.002</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.0006</td> <td>    0.001</td> <td>    0.757</td> <td> 0.449</td> <td>   -0.001</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -1.0598</td> <td>    0.021</td> <td>  -50.684</td> <td> 0.000</td> <td>   -1.101</td> <td>   -1.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    0.0071</td> <td>    0.000</td> <td>   45.446</td> <td> 0.000</td> <td>    0.007</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>   -0.0082</td> <td>    0.005</td> <td>   -1.579</td> <td> 0.114</td> <td>   -0.018</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>   -0.0600</td> <td>    0.041</td> <td>   -1.467</td> <td> 0.143</td> <td>   -0.140</td> <td>    0.020</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>59331.376</td> <th>  Durbin-Watson:     </th>  <td>   1.994</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>732227.779</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 2.664</td>   <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>15.138</td>   <th>  Cond. No.          </th>  <td>8.12e+03</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 8.12e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  visit   R-squared:                       0.278\n",
       "Model:                            OLS   Adj. R-squared:                  0.278\n",
       "Method:                 Least Squares   F-statistic:                     2968.\n",
       "Date:                Mon, 12 Dec 2022   Prob (F-statistic):               0.00\n",
       "Time:                        10:51:13   Log-Likelihood:                 30879.\n",
       "No. Observations:              100000   AIC:                        -6.173e+04\n",
       "Df Residuals:                   99986   BIC:                        -6.160e+04\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          4.6387      0.139     33.426      0.000       4.367       4.911\n",
       "x1             0.0040      0.002      2.534      0.011       0.001       0.007\n",
       "x2            -0.0005      0.000     -3.427      0.001      -0.001      -0.000\n",
       "x3            -0.0078      0.008     -1.021      0.307      -0.023       0.007\n",
       "x4            -0.0895      0.003    -31.384      0.000      -0.095      -0.084\n",
       "x5            -0.0012      0.001     -1.973      0.049      -0.002   -8.07e-06\n",
       "x6             0.0351      0.003     10.312      0.000       0.028       0.042\n",
       "x7            -0.0080      0.003     -2.893      0.004      -0.013      -0.003\n",
       "x8            -0.0018      0.000     -9.964      0.000      -0.002      -0.001\n",
       "x9             0.0006      0.001      0.757      0.449      -0.001       0.002\n",
       "x10           -1.0598      0.021    -50.684      0.000      -1.101      -1.019\n",
       "x11            0.0071      0.000     45.446      0.000       0.007       0.007\n",
       "x12           -0.0082      0.005     -1.579      0.114      -0.018       0.002\n",
       "x13           -0.0600      0.041     -1.467      0.143      -0.140       0.020\n",
       "==============================================================================\n",
       "Omnibus:                    59331.376   Durbin-Watson:                   1.994\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           732227.779\n",
       "Skew:                           2.664   Prob(JB):                         0.00\n",
       "Kurtosis:                      15.138   Cond. No.                     8.12e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 8.12e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac75834",
   "metadata": {},
   "source": [
    "# Distribution of Theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66d67e46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+-------+------------+-------+-------+--------+--------+\n",
      "|         Estimator          | θ_hat | s.e(θ_hat) |   t   |   p   |  2.5%  | 97.25% |\n",
      "+----------------------------+-------+------------+-------+-------+--------+--------+\n",
      "|            OLS             | 0.004 |   0.002    | 2.534 | 0.011 | 0.001  | 0.007  |\n",
      "|          Naive-ML          | 0.001 |   0.000    | 4.659 | 0.000 | 0.001  | 0.002  |\n",
      "|          Ortho-ML          | 0.001 |   0.001    | 2.034 | 0.042 | 0.000  | 0.002  |\n",
      "| OrthoML+Crossfitting (DML) | 0.003 |   0.002    | 1.612 | 0.107 | -0.001 | 0.006  |\n",
      "+----------------------------+-------+------------+-------+-------+--------+--------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "MC_θ = np.c_[theta_ols, theta_nonorth, theta_orth_nosplit, theta_dml]\n",
    "MC_se = np.c_[se_ols, se_nonorth, se_orth_nosplit, se_dml]\n",
    "\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Estimator', 'θ_hat', 's.e(θ_hat)','t','p','2.5%','97.25%']\n",
    "a = ['OLS']+ np.c_[results.params[1], results.bse[1], results.tvalues[1], results.pvalues[1], results.conf_int(alpha=0.05, cols=None)[0][1], results.conf_int(alpha=0.05, cols=None)[1][1]].reshape(-1).tolist()\n",
    "table.add_row(a)\n",
    "a = ['Naive-ML']+ np.array(obj_dml_plr_nonorth.summary).reshape(-1).tolist()\n",
    "table.add_row(a)\n",
    "a = ['Ortho-ML']+ np.array(obj_dml_plr_orth_nosplit.summary).reshape(-1).tolist()\n",
    "table.add_row(a)\n",
    "a = ['OrthoML+Crossfitting (DML)']+ np.array(obj_dml_plr.summary).reshape(-1).tolist()\n",
    "table.add_row(a)\n",
    "table.float_format = '0.3'\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9027bc2",
   "metadata": {},
   "source": [
    "# First Stage Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9b7a705",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "OLS_Y = LinearRegression()\n",
    "OLS_D = LogisticRegression()\n",
    "RF_Y = RandomForestRegressor()\n",
    "RF_D = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a419c862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+-------+\n",
      "|       Model       |  OLS  |   RF  |\n",
      "+-------------------+-------+-------+\n",
      "|    Y on X (R2)    | 0.278 | 0.898 |\n",
      "| D on X (Accuracy) | 0.851 | 1.000 |\n",
      "+-------------------+-------+-------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "MC_θ = np.c_[theta_ols, theta_nonorth, theta_orth_nosplit, theta_dml]\n",
    "MC_se = np.c_[se_ols, se_nonorth, se_orth_nosplit, se_dml]\n",
    "\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Model', 'OLS', 'RF']\n",
    "a = ['Y on X (R2)'] + [OLS_Y.fit(x,y).score(x,y), RF_Y.fit(x,y).score(x,y)]\n",
    "table.add_row(a)\n",
    "a = ['D on X (Accuracy)'] + [OLS_D.fit(x,d).score(x,d), RF_D.fit(x,d).score(x,d)]\n",
    "table.add_row(a)\n",
    "table.float_format = '0.3'\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dde0ce6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf407b88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
